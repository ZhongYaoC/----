TCP、UDP比较

| 区别               | TCP                                                          | UDP                                                          |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 连接               | 有连接，传输前先连接                                         | 无连接，即刻传输                                             |
| 服务对象           | 一对一                                                       | 一对一、一对多、多对多                                       |
| 可靠性             | 可靠；不丢失、无重复、按序到达                               | 不可靠，尽最大努力交付                                       |
| 拥塞控制、流量控制 | 有                                                           | 无                                                           |
| 首部开销           | 至少20字节（无选项字段）                                     | 8字节，固定                                                  |
| 传输方式           | 流式传输，字节流，无边界                                     | 一个包一个包传输，有边界                                     |
| 分片               | 传输层如果超出MSS即分片；目标主机收到后在传输层组装，中途数据丢失则只传输此分片 | 网络层中如果超出MTU即分片；目标主机收到后在网络层组装，然后交给传输层 |
| 常见应用           | FTP、HTTP/HTTPS、TELNET                                      | DNS、SNMP、音视频传输、广播通信                              |
|                    |                                                              |                                                              |



### 为什么是三次握手？不是两次、四次？

![TCP三次握手](.\Backend Learning\图片\网络八股\TCP三次握手.png)



* 三次握手可以防止**历史连接**的建立

假设使用两次握手连接，客户端发送SYN报（90）因网络阻塞未到达，此时客户端重新发起连接，发出新的SYN（100）报，这是旧的SYN（90）报到达服务端，服务端发出ACK（90+1）报，确认旧的SYN，如果使用二次握手即连接，此时服务端可以发送数据，当客户端收到旧的SYN的ACK，发现不是自己需要的ACK（100+1），故发送RST报文，导致服务端发出的数据完全浪费；

而在三次握手下，因未建立连接此时服务端不能发送数据，发出的旧的SYN的ACK会收到RST，从而避免了资源浪费。

而如果在RST报到达服务端之前，服务端收到新的SYN（100）报，此时的服务端会发送challenge ack报文给客户端，此ACK的内容为（90+1），因为还没收到RST，服务端认为还是原来的连接，客户端收到此ACK（90+1）后再次发送RST。

* 同步双方的初始序列号

初始序列号对于报文的有序到达、去重复、标识数据包非常重要，所以需要在客户端和服务端之间达成一致，沟通双方的初始序列号，此过程至少需要三次传输，如果使用四次造成浪费。

* 避免资源浪费

假设使用两次握手连接，类似1中的历史连接将会导致服务器端分配多次连接，造成资源浪费。



### 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

* 尽可能避免历史报文被下一个相同的四元组连接接受（只是尽可能避免，不是完全，因为序列号还有回绕问题，所以实践中会结合时间戳）
* 安全性，防止有人伪造相同序列号的TCP报文



### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

假设不存在MSS，仅存在MTU，那么当发送的数据大小超出MTU时，IP层需要分片传输，并在接收方的IP层组装并上交给传输层。但是，**IP层本身没有超时重传等可靠性措施**，一旦某个分片传输时丢失，那么IP层无法组装完成，从而无法上交传输层，传输层迟迟无法发出ACK，导致对端的传输层触发超时重传，但此时传输层重传的数据量仍然超出MTU，部分分片的丢失，导致了全部报文的重传！传输效率低下。

所以为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。



### 三次握手报文丢失的处理

报文丢失之后的处理均为重传，但是区别在于：第一次握手的SYN报文、第二次握手的SYN-ACK报文如果一直没有收到对应的ACK都会重传，而第三次握手的ACK报文如果丢失，将触发第二次握手的SYN-ACK重传，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

而每次重传的次数由操作系统内核参数确定

```bash
cat /proc/sys/net/ipv4/tcp_syn_retries
cat /proc/sys/net/ipv4/tcp_synack_retries
```



### SYN攻击及避免

假设攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

半连接队列：收到第一次握手报文后，放置到半连接队列

全连接队列：三次握手完成后，放置到全连接队列

`listen()`系统调用后，服务端开启监听，此时收到的第一次握手均会放置到半连接队列，而`accept()`会从全连接队列中取出连接对象。客户端调用`connect()`后会发出握手报文，当三次握手结束，则返回（阻塞模式下）

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，**默认情况都会丢弃报文**。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。



#### 避免

* 调大 `netdev_max_backlog`

当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值的参数即为`netdev_max_backlog`；

* 增大半连接队列

以Linux内核2.6.32为例，通过**同时**

增大 `net.ipv4.tcp_max_syn_backlog`；

增大 `listen()` 函数中的 `backlog`参数；

增大 `net.core.somaxconn`

实现半连接队列的增大

> `int listen(int sockfd, int backlog);`
>
> 其中参数`backlog`最早代表半连接队列的大小，Linux内核2.2之后，`backlog`代表**已完成连接队列**的大小。
>
> 不过已完成连接队列的实际值收到内核参数`net.core.somaxconn`的限制，所以**已完成连接队列**的大小 = `min(somaxconn, backlog)`;



* 使用`tcp_syncookies`

`tcp_syncookies`的作用为收到SYN报文之后，即使半连接队列已满也不丢弃，而是生成一个cookies值，将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。

`tcp_syncookies`有三个参数值可选，0-关闭，1-当半连接队列已满时开启，2-无条件开启

```bash
echo 1 > /proc/sys/net/ipv4/tcp_syncookies
```

* 减少`SYN-ACK`重传次数

由于SYN攻击时，攻击方不会回应ACK，即第三次握手报文，服务端会认为SYN-ACK报文丢失，从而不断重传，达到重传次数上限才会断开连接，所以可以减少SYN-ACK报文重传次数从而加快断开连接。



### 关闭连接

![四次挥手](.\Backend Learning\图片\网络八股\四次挥手.png)

注意：**主动关闭连接的，才有 TIME_WAIT 状态**

### 为什么是四次挥手

关闭连接时，客户端发出`FIN`，表示客户端不再向服务端发送数据，但还能够接收服务端的数据，服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

所以通常`FIN`和`ACK`不会合成一个报文，故需要四次挥手；不过特殊情况下，也可以变为三次挥手。

### 挥手报文丢失

如果挥手报文丢失仍然是重传。

* 第一次挥手报文如果丢失，将会超时重传，如果超出重传上限仍未能收到对应的`ACK`，则会等待一段时间（上次超时时间的2倍），如果还是未收到`ACK`，则**直接进入`CLOSE`状态**。重传次数由`tcp_orphan_retries`决定；

* 第二次挥手报文丢失，因为`ACK`不会重传，所以和第一次挥手丢失情况相同。

因为接收到`ACK`报文后进入`FIN_WAIT_2`状态，如果是因`close()`触发的关闭连接，则客户端（主动关闭方）不会一直等待服务端的`FIN`报文，而是等待一段时间后，如果没有收到`FIN`报文，将会直接关闭进入`CLOSE`状态。等待的时间段由`tcp_fin_timeout`决定，默认60s。

而如果是因`shutdown()`函数关闭连接，且指定了关闭发送而不关闭接收，则客户端（主动关闭方）会一直处于`FIN_WAIT_2`状态，直到收到来自服务端的`FIN`报文为止。此时`tcp_fin_timeout`无效。





当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 `ACK`，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待**本方的应用进程**调用 `close()` 函数关闭连接。因为此时内核是没有权利替代进程关闭连接，必须由进程主动调用 `close()` 函数来触发服务端发送 `FIN` 报文。

服务端处于 `CLOSE_WAIT` 状态时，调用了 `close()` 函数，内核就会发出 `FIN` 报文，同时连接进入 `LAST_ACK` 状态，等待客户端返回 `ACK` 来确认连接关闭。

* 第三次挥手报文丢失，如果迟迟收不到对应的 `ACK`，服务端就会重发 `FIN` 报文，重发次数仍然由 `tcp_orphan_retries`参数控制，这与客户端重发 `FIN` 报文的重传次数控制方式是一样的。

因为客户端（主动关闭方）如果因`close()`调用而关闭，则不会一直处于`FIN_WAIT_2`状态，可能已经关闭了连接，所以服务端（被动关闭方）在一直未收到`ACK`报文下，会进入`CLOSE`状态。





* 当客户端（主动关闭方）收到对端的`FIN`报文，会进入`TIME_WAIT`状态，并维持`2MSL`时间，并发出`ACK`报文回应，如果此报文丢失，则服务端（被动关闭方）由于长期未收到`ACK`，会重传第三次的`FIN`报文，所以重传规则如第一次。

客户端（主动关闭方）如果收到对端的`FIN`报文，将会重置定时器，重新等待`2MSL`时间。



### 为什么 TIME_WAIT 等待的时间是 2MSL

`MSL`即$Maximun Segment Lifetime$，报文最长生存时间，是报文在网络中存在的最长时间，超出则丢弃；类似于IP层中的`TTL`字段，`TTL`指IP数据报可以经过的路由器最大数量，每经过一个路由器即减一，为0则丢弃，所以`MSL`要大于`TTL`为0所耗的时长；一般`TTL`值为64，而Linux中`MSL`设置为30s，即认为经过64个路由器所用的时间最长不超过30s。

至于`2MSL`则是指一来一回所用的时间，如果客户端（主动关闭方）收到对端FIN报文，会重置2MSL，重新等待。

如果修改`MSL`的默认值，需要修改内核并重新编译。



### 为什么需要TIME_WAIT状态

**只有主动关闭方才会有`TIME_WAIT`状态。**

* 防止（同四元组的）历史连接中的数据报造成扰乱

![TIME_WAIT REASON 1](C:\Users\Zhong\Downloads\SCU\Backend Learning\图片\网络八股\TIME_WAIT REASON 1.png)

如果跳过`TIME_WAIT`状态/`TIME_WAIT`状态过短，而此时立即新建立同四元组的连接，那么如果上一次连接中阻塞在网络中的历史报文的序列号恰好在本次连接的窗口范围内（因为序列号回绕等原因），那么新连接将会错误的接收历史连接报文。

所以`TIME_WAIT`状态会等待`2MSL`时间，相当于等待一个网络来回，将所有可能到达的阻塞网络报文全部在本次连接中自然消失，而不会影响到下一次连接。

* 保证被动关闭的一方正确关闭

![TIME_WAIT REASON 2](C:\Users\Zhong\Downloads\SCU\Backend Learning\图片\网络八股\TIME_WAIT REASON 2.png)

如果跳过`TIME_WAIT`状态/`TIME_WAIT`状态过短，导致主动关闭方直接`CLOSE`，此时主动关闭方的第四次挥手`ACK`又发生丢失，那么被动关闭方重发的第三次挥手`FIN`报文将会被主动方以`RST`报文回复，那么被动关闭方将会因异常终止。因`RST`而关闭不够优雅。



**更多**

在`TIME_WAIT`状态下收到`SYN`、`RST`及其他类型报文该如何处理：

1、收到`SYN`报文

首先检查是否合法：1）时间戳是否大于最后一个收到报文的时间戳；2）序列号是否大于期望收到的下一个序列号；如果都大于则为合法，否则不合法；

合法`SYN`：重新开始连接，`TIME_WAIT`转为`SYN_RECV`状态

不合法`SYN`：回复之前的第三次挥手`ACK`，接收方将会因为序列号不匹配而回复`RST`报文

2、收到`RST`报文

Linux下，在`TIME_WAIT`时收到`RST`由内核参数`net.ipv4.tcp_rfc1337`决定，此参数分为0，1两种；

0 - 收到`RST`提前结束`TIME_WAIT`，释放连接；

1 - 丢弃`RST`；

3、收到其他类型报文 `TCP_TW_SUCCESS`

直接丢弃，不做响应



### TIME_WAIT 优化及为何出现大量TIME_WAIT

大量连接处于`TIME_WAIT`状态主要危害在于：

1）占用系统资源：内存、文件描述符、CPU、线程等

2） 占用端口资源（一般为`net.ipv4.ip_local_port_range = 32768 61000`）

假设客户端（主动断开方）向同一「目的 IP+ 目的 PORT 」的服务端建立连接，如果存在大量`TIME_WAIT`状态，导致端口被占满，那么无法建立新的向此服务端的连接，但是正在使用的端口可以继续连接；若向其他IP+Port连接，端口可以重复使用，因为内核中定位连接使用四元组，而非端口号定位。

#### 优化

1）打开 `net.ipv4.tcp_tw_reuse` 和 `net.ipv4.tcp_timestamps` 选项

`net.ipv4.tcp_tw_reuse`开启此参数后，内核会允许复用处于TIME_WAIT状态的连接，但只能用于客户端，因为开启此参数后，内核会在调用`connect()`函数时，随机找一个TIME_WAIT状态超过1s的连接给新的连接复用。

但是此功能需要开启时间戳后，才会生效。

**仅适用于需要调用`connect()`的客户端**



2）程序中使用`SO_LINGER`

《UNIX网络编程》书中对`SO_LINGER`描述为套接字的发送缓冲区内残留的待发送数据处理方式，以及```close()```返回的时机。

```c
struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
```

如果设置为上述参数，则`close()`调用后会直接丢弃发送缓冲区数据，向对方发送`RST`报文，从而跳过`TIME_WAIT`状态，关闭连接。



3）`net.ipv4.tcp_max_tw_buckets`

这个值默认为 18000，**当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置**，这个方法比较暴力？？

Q：重置？哪种方式的重置？



4）扩大可用的端口数量

修改内核中的`net.ipv4.ip_local_port_range`参数，扩大可用端口数



以上措施很多都是基于跳过`TIME_WAIT`状态设置，但是恰如《UNIX网络编程》一书中却说道：**`TIME_WAIT` 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它**，所以不要盲目终止`TIME_WAIT`



#### SO_LINGER

```C++
struct so_linger
{
    int l_onoff;
    int l_linger;
};

setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
```


默认`close()`调用后，默认是引用计数减1，并立即返回，并发送发送缓存区中的数据，也就是说`close()`返回不代表已经接收到对端的`ACK`。

所以新增`l_linger`设置一个时延，此段时间内（没进入`CLOSE`状态）如果收到对端`ACK`，则`close()`正常返回，否则返回`EWOULDBLOCK`。

但是仍然存在问题：

收到对端发来的`ACK`，并不代表对端已经读取，只能说明对端的`TCP`协议栈收到了，但不一定`read()`，`read()`前服务端完全有可能崩溃；为解决这个问题只能在应用层发送自定义的`ACK`，然后客户端`read`到这个`ACK`后再`close()`。

```C++
#include <sys/socket.h>
int shutdown(int sockfd, int howto);

// howto:
// SHUT_RD(0)
// 关闭接收，丢弃接收缓存区数据，新的接收数据将直接丢弃
// SHUT_WR(1)
// 关闭发送，先将发送缓存区中数据全部发送，然后发送FIN（无视引用计数），此后不能调用写函数
// SHUT_RDWR(2)
// 等效于 调用两次shutdown()
```

 `close()`函数将会使引用计数减一，如果引用计数不为0，将不会发送FIN报文给对端；但是`shutdown()`函数将可以无视引用计数，直接发送FIN报文，从而触发连接关闭。同时`close()`函数将会关闭发送和接收方向的数据传送，但是`shutdown()`函数可以自行决定关闭的方向。




| 函数                                  | 意义                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| close with l_onoff = 0 (default)      | 默认的处理方式；close调用后**立即返回**，套接字**不能发送或接收请求**：套接字发送缓存区的数据将会发送，如果套接字引用计数为0，则发送FIN，并抛弃接收缓存区内容 |
| close with l_onoff = 1, l_linger = 0  | close调用后立即返回，套接字**不能发送或接收请求**：发送和接收缓存区的数据将会被抛弃，同时向对端发送`RST`，跳过TIME_WAIT直接进入CLOSE |
| close with l_onoff = 1, l_linger != 0 | 套接字**不能发送或接收请求**：套接字发送缓存区的数据将会发送，如果套接字引用计数为0，则发送FIN，并抛弃接收缓存区内容；如果在连接变为CLOSE前延迟时间(l_linger)到，close将返回EWOULDBLOCK错误 |
| shutdown with SHUT_RD                 | 套接字**不能接收请求**，仍可向套接字中发送数据，接收缓存区中数据丢弃，新收到数据丢弃，对发送缓存区无影响 |
| shutdown with SHUT_WR                 | 套接字**不能发送请求**，仍可从套接字中接收数据，将发送缓冲区中数据发送完毕后，发送`FIN`报文，对接收缓存区无影响 |





### 服务器出现大量 TIME_WAIT 状态的原因有哪些？

因为`TIME_WAIT`状态只有主动关闭方才会出现，所以服务器端出现大量TIME_WAIT说明服务器主动关闭了`TCP`连接。可能的原因有：

1）HTTP没有使用长连接

HTTP中如果设置keepalive参数，那么客户端和服务端之间的请求-响应将会在同一个`TCP`连接下完成，而不是每一个请求-响应使用单独的`TCP`连接。

如果客户端和服务端的任意一端没有设置keepalive（即不使用长连接），那么**都将由服务器端负责关闭连接**。

> 当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。
>
> 为什么要这么设计呢？在服务端主动关闭连接的情况下，只要调用一次 close() 就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次 syscall；如果是要求 客户端关闭，则服务端在写完最后一个 response 之后需要把这个 socket 放入 readable 队列，调用 select / epoll 去等待事件；然后调用一次 read() 才能知道连接已经被关闭，这其中是两次 syscall，多一次用户态程序被激活执行，而且 socket 保持时间也会更长。
>
> WHY？三次握手、四次挥手中TCP栈负责哪些东西的处理？？？哪些东西需要主动的系统调用！

2）HTTP长连接超时

未防止建立长连接之后，两端长期没有数据交互而造成连接资源浪费，像nginx会为每个长连接维护一个计时器，如果计时器时长内没有新的请求，那么触发回调函数，由服务器端主动关闭长连接。

排查时可以检查网络连接，是否因为网络故障导致客户端的请求未被接收。

3）HTTP长连接的请求数量达到上限

Web服务器中一般会为每个长连接设置可以执行的最多的请求数量，如nginx 的 keepalive_requests 这个参数（默认100），这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。**如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接**，那么此时服务端上就会出现 `TIME_WAIT` 状态的连接。



### 服务器出现大量 CLOSE_WAIT 状态的原因有哪些

`CLOSE_WAIT`是被动关闭方才会有的状态，此状态表示等待主动调用`close()`函数，如果一直没有调用，将会无法进入`LAST_ACK`状态。出现大量`CLOSE_WAIT`状态就说明服务端一直没有调用`close()`去关闭连接。

大概率是代码逻辑问题，如`listen()`的fd或者`accept()`到的fd等等没有注册到epoll或者select中，导致没有感知到对端的FIN报文，更或者干脆自己忘记调用`close()`了。



### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

此处的客户端故障特指主机侧的宕机或断电重启等故障，而非进程崩溃，也不是主机正常关机。

可以开启TCP中的`SO_KEEPALIVE`选项，同时Linux中可以修改内核参数以定制keepalive行为。

KeepAlive机制：如果客户端和服务端长期没有活动，TCP保活机制会每个一段时间，发送一个探测报文，连续几个探测报文没有响应则认为对端已经不可达，内核将通知给上级应用程序。KEEPALIVE只适合探测主机故障。

Linux内核参数：

```C++
net.ipv4.tcp_keepalive_time=7200 // 多久没有活动后发出探测报文，7200s
net.ipv4.tcp_keepalive_intvl=75  // 每个探测报文的间隔时长，75s
net.ipv4.tcp_keepalive_probes=9  // 累计多少个探测报文后认定对端不可达，9次
```

1）对端正常

发送探测报文后，对端会正常响应，保活时间会重置

2）对端已宕机

对端无响应，认定对端不可达

3）对端断电后已重启

对端此时可以响应，但是重启后原连接数据已经清空，所以回复`RST`。

推荐应用端自行实现心跳机制，更快感知对端故障。

### 没有 listen，能建立 TCP 连接吗？

答案：**可以的**。

客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**



### 端口复用

#### UDP、TCP使用同一端口号

`UDP`和`TCP`使用同一个端口号，是因为在上交至传输层之前，`IP`层可以根据头部的「协议号」字段知晓对应协议，从而交给不同的传输层模块处理。

#### 服务端-TCP绑定bind同一端口

正常情况下，一个正在使用的IP+PORT连接，如果重复启动，后启动的连接在`bind()`时会报错“Address already in use”；

而更常见的情况是，关闭上一个连接，然后重启，如果上一个连接正处于`TIME_WAIT`状态，后启动的连接同样会报错“Address already in use”。

其他，如 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。因为0.0.0.0表示任意地址，包含192.168.1.100地址，和后续同端口的连接冲突。

为解决上述问题，可以在**`bind()`之前**，设置TCP的`SO_REUSEADDR` 属性，那么针对处于`TIME_WAIT`状态的连接，如果设置了`SO_REUSEADDR`，内核将会允许绑定成功，从而帮助更快的重启服务。

```C++
int on = 1;
setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &on, sizeof(on));
```

`SO_REUSEADDR`的另一个作用：

绑定的IP+PORT时，只要IP地址不是完全（**exactly**）匹配，就可以绑定成功。

如 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是192.168.1.100 地址（或者其他地址）和端口 8888，设置了`SO_REUSEADDR`属性，那么也会`bind()`成功。

> PS：不要使用SO_LINGER参数来实现快速重启服务，因为SO_LINGER是通过跳过TIME_WAIT状态来直接关闭连接，从而起到防止端口冲突，但《UNIX网络编程》一书中专门提到，TIME_WAIT不是坏事，不要试图跳过他。

#### 客户端-端口重复使用

通常使用`connect()`连接时，内核会随机选择一个有效端口号，作为源端口，而内核在定位一个连接时，通过四元组（源IP+PORT，目的IP+PORT）来定位，所以只要连接的四元组中任一值不同即视为不同连接，即允许端口重复使用。

当然，客户端也可以调用`bind()`绑定自己的源地址。

客户端如果出现大量`TIME_WAIT`状态，如果全部是与同一服务器（同目的IP+PORT）连接，那么当端口耗尽，就无法连接；但如果是与不同服务器连接，那么可以继续连接，短板取决于其他设备资源。

客户端大量`TIME_WAIT`状态可以设置内核参数`tcp_tw_reuse`，将那些`TIME_WAIT`状态超出1s的连接复用。

![](.\Backend Learning\图片\网络八股\客户端发起连接.png)

#### SO_REUSEADDR、SO_REUSEPORT

`SO_REUSEADDR`

1）针对常见的多进程/多线程Web服务端，如果负责监听的进程崩溃，而其他已完成连接正常运行，此时重启监听进程，因为试图绑定的端口和已经存在的连接冲突，`bind()`会调用失败；所以需要`bind()`之前设置`SO_REUSEADDR`；当然针对`TIME_WAIT`状态，同样需要。

2）服务器绑定多个IP地址，但端口相同，这在托管着多个http服务器的站点很常见，如果服务器先绑定一个`INADDR_ANY`和端口4566，然后绑定其他的ip地址（如192.168.10.13）和端口4566，`bind()`会调用失败；所以需要`bind()`之前设置`SO_REUSEADDR`。即之前提到的绑定的IP+PORT时，只要IP地址不是完全（**exactly**）匹配，就可以绑定成功；

3）`SO_REUSEADDR`允许单个进程捆绑同⼀端⼝到多个套接字 上，只要每次捆绑指定不同的本地IP地址即可；

4）针对UDP而言，`SO_REUSEADDR`允许**完全重复的捆绑**（捆绑相同IP地址和相同端口号），但是TCP不允许；UDP主要是针对组播/多播而允许启动多个绑定同IP+PORT的副本。

所以建议每个服务端启动`SO_REUSEADDR`参数。



`SO_REUSEPORT`

1）本选项允许**完全重复的捆绑**，不过只有在想要捆绑同⼀IP地址 和端口的每个套接字都指定了本套接字选项才行；

2） 如果被捆绑的IP地址是⼀个多播地址，那么`SO_REUSEADDR`和 `SO_REUSEPORT`被认为是等效的









### TCP 重传、滑动窗口、流量控制、拥塞控制



### 全连接、半连接队列

全连接队列即accept队列，半连接队列即SYN队列

#### 全连接队列

当全连接/半连接队列满后，收到的连接将会丢弃；全连接队列的最大长度为`min(backlog, /proc/sys/net/core/somaxconn)`，全连接队列的长度可以通过`ss`命令查看：

![全连接队列长度查看1](.\Backend Learning\图片\网络八股\全连接队列长度查看1.png)

其中LISTEN状态时，Recv-Q表示当前全连接队列长度，Send-Q表示全连接队列最大长度，上图中为0和128；

![全连接队列长度查看2](.\Backend Learning\图片\网络八股\全连接队列长度查看2.png)

但非LISTEN状态时，Recv-Q表示当前接收但未被应用处理的字节数，Send-Q表示已发送后未收到ACK的字节数，上图中为0和850字节



#### 半连接队列

Linux内核中设置了系统参数 `net.ipv4.tcp_max_syn_backlog`，但是半连接队列的最大长度不是仅由此参数定义，Linux2.6版本中，判定半连接队列是否超出使用三个参数同时判定，最大长度即为`min(min(somaxconn, backlog), tcp_max_syn_backlog) * 2 `，而Linux5.0.0版本中最大长度即为全连接队列的最大长度。

但不论哪个Linux版本，收到SYN后都需要三步检测

```C++
// 前提：未开启syn_cookies

if (半连接队列超出)
    drop;
if (全连接队列超出)
    drop;
if (tcp_max_syn_backlog - 当前半连接队列长度 < tcp_max_syn_backlog >> 2)
    drop;
```

也就是说，如果当前半连接队列未超出最大值，但是其长度大于 `tcp_max_syn_backlog  - tcp_max_syn_backlog >> 2`仍然会丢弃收到的SYN报文。



故Linux2.6版本中扩容半连接队列需要同时增大`tcp_max_syn_backlog, backlog, somaxconn`；

Linux中没有直接的命令查看半连接队列大小，但可以根据收到SYN后进入的`SYN_RECV`状态来推测半连接队列大小，`netstat -natp | grep SYN_RECV | wc -l`，同时通过仅发送SYN但不回复ACK（SYN攻击）来模拟半连接队列堆积。

![半连接队列长度查看](.\Backend Learning\图片\网络八股\半连接队列长度查看.png)





### TIPS：

如何感知`FIN`报文：

服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到**接收缓冲区**中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。

读到EOF后，read似乎返回0？
