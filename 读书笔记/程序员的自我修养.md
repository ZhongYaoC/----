#### 第一章 回忆章

##### Bus

最初的CPU、内存、IO使用同一个总线（Bus），此时的CPU频率和内存相差无几，而IO设备速度相交差距较大，所以每个IO设备有专门的IO控制器，协调与CPU内存间的通信；随后CPU频率提升极快，远超内存频率，所以采用与内存频率一致的系统总线，CPU通过倍频的方式和内存通信，之后随着图形显示需求的提升，图形芯片与CPU、内存间的有大量的通信需求，所以设计出高速的北桥芯片（Northbridge，PCI Bridge），负责图形芯片和CPU、内存间的通信需求，但是如果把其他慢速IO也挂载在北桥芯片，北桥芯片就需要同时处理高速和慢速设备，设计会非常复杂，所以设计南桥芯片专门负责低速设备，USB、鼠标、磁盘等设备通过南桥汇总后连接在北桥上。

其中系统总线使用PCI结构，南桥使用ISA总线，PCI结构后续出现的有PCIExpress，AGP等

##### SMP和多核

随着摩尔定律遇到物理瓶颈，无法一味提升CPU主频，所以出现了提高CPU数量的做法，其中每个CPU在内部处理的功能完全一致，相互对称，所以称为SMP（对称多处理器），但是物理上的多处理器造价较高，所以厂商将多个处理器整合到一起，并共用造价高昂的缓存设备，就出现了多核设备。

但是，程序不一定能够天然的拆分成不同部分，并交由不同的CPU处理，所以多核编程不是想象的那么简单，so

Free Lunch is Over！

##### 软件层次结构	

> “计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决”
>
> “Any problem in computer science can be solved by another layer of indirection.”
>
> 看完Effective C++感觉略有感触，EC++中很多面向对象的解决方案中其实就是增加一个间接层，如继承接口类，pimpl

层次结构，其中[]中标注为下层为上层提供的接口协议Interface

Application + Develop Tool

[应用程序编程接口（Application Programming Interface）]

RunTime Library

[系统调用]

Operation Kernel

[硬件规格（Hardware Specification）]

Hardware

##### 内存

分段式

分页式：请求分页调度，虚拟内存，缺页中断

程序的局部性！！

##### 线程

###### 线程访问权限![线程和进程资源界限](..\图片\程序员的自我修养-images\线程和进程资源界限.jpg)

TLS: Thread Local Storage，线程局部存储是某系OS为线程单独提供的私有空间，通常只有很有限的容量。



###### Linux下的进程、线程概念

Linux中没有真正意义上的线程概念，将执行实体（无论是进程还是线程）成为任务（Task），每个任务默认类似于单线程的进程，而这些任务可以选择共享内存，此时共享了同一个内存的任务称为一个进程，而这些任务就成了进程内的线程。

fork() 复制当前进程，采取COW（Copy On Write 写时复制）

exec() 而fork是单纯的复制当前任务，如果要在内部执行新的任务，那么需要exec以启动其他任务

clone() 可以生成一个新任务，从指定位置执行，并可以选择共享当前的内存空间，所以效果上即为产生一个线程

###### 同步和锁

信号量 Semaphore：二元信号量只有两种状态，占用和未占用，某线程持有此资源后，只有释放才可以被其他线程占用，适合被单一线程独占资源；多元信号量可以被多个线程同时占用，每增加一个线程占用，信号量--，当信号量小于0，则不允许被其他线程占用；线程释放信号量，则信号量++，只有当信号量大于0才可以被其他线程占用

互斥量 Mutex：和二元信号量类似，资源仅允许一个线程占用

临界区 Critical Section：比互斥量更严格，但是其实很类似

> 二元信号量和互斥量区分：
>
> 二元信号量可以被一个线程获取之后由另一个线程释放，互斥量要求哪个线程获取，即由哪个线程释放
>
> 二元信号量和互斥量和临界区区分：
>
> 二元信号量和互斥量在系统的所有进程可见，临界区作用范围仅限本进程，其他进程无法获取该锁

读写锁 Read-Write Lock：

条件变量 Condition Variable：



###### 可重入和线程安全

有了锁的保护之后，从程序代码来看，基本的线程安全是可以保证的，但是实际运行时还需要考虑编译器和CPU的优化，此类优化一般是为了加快运行速率，但是有时优化会变成过度优化，反而影响线程安全。

编译器优化：

* 为提高运行速率，将一个变量缓存到寄存器而不写回
* 交换互不相关的相邻指令（但是多线程时这些指令反而有了关联）

使用`volatile`关键字阻止以上优化，`volatile`变量不会被缓存到寄存器不写回，也不会被交换指令顺序

CPU优化：

* CPU动态调度换序，CPU也会将无关联的指令更换顺序

使用`barrier()`指令（此指令由CPU提供），`barrier`指令会阻止CPU将`barrier()`前面的指令换到`barrier()`之后

#### 第二章 编译和链接

###### 预编译

由预编译器负责

将`#define`删除，并展开所有宏定义；

处理所有**预编译指令**，如`#ifndef #endif `；

将`#include`指定的头文件全部插入到指令所在位置（可递归进行）；

删除所有注释；

添加行号和文件名标识，以便编译时编译器产生调试用的行号信息以及编译错误或警告时显示行号；

保留所有`#pragma`**编译器指令**，因为编译器需要使用

###### 编译

经过一系列的词法分析、语法分析、语义分析及源码优化后，将文件转换为汇编语言

###### 汇编

将汇编转换为二进制，即汇编到二进制的逐个翻译

###### 链接

由链接器负责



###### 编译器的具体步骤

编译步骤：扫描、语法分析、语义分析、源代码优化（前四者属于编译器前端）、代码生成、目标代码优化（属于编译器后端）

* 词法分析：将源码的字符序列分割为一系列的记号（token），同时将标识符存放到符号表，数字和字符串常量存放在文字表，以备后用

* 语法分析：将token转化为语法树，但此时并不理解各个符号代表什么意思，合不合法，括号等是否匹配

* （静态）语义分析：给语法树中的表达式标识类型；静态语义包含声明和类型的匹配，类型转换

* 中间语言生成：对上述标识了类型的语法树进行优化，如代码中的数字计算（如3+8等）直接优化为结果，而在语法树上直接优化较为困难，所以将语法树转换为中间代码（Intermediate Code），是语法树的顺序表示，而且中间代码不依赖于运行环境。

  常见的中间代码如：三地址码，P-代码；三地址码（`x = y op z`）

* 代码生成：将中间代码转换为目标机器代码，此过程依赖于目标机器，因为不同的机器有着不同的寄存器、字长、整数、浮点类型等，所以编译器需要能够支持各种CPU类型，以生成多种目标CPU代码

* 目标代码优化：对上述目标机器代码优化，如选择合适的寻址方式，使用位移来代替乘法运算，删除多余的指令

经此已生成目标代码（之后还要汇编），但是欠缺关键的地址信息，地址还未确定，即变量到底存放在哪里；如果这个变量的定义和源代码来自于同一个编译单元，那么编译器可以分配内存空间，但如果此变量定义在另一个模块（**C语言中一个.c文件就是一个模块**）中，就需要在链接时才能确定地址



> PS：计算机相关的知识很多时候，了解其发展历史，可以更好的理解为什么会有当前的现状，因为当前的设计不一定是最好的，但却是对当年早期某些设计的妥协或者兼容



###### 链接器

多个模块之间需要通信，对于属于静态语言的C++而言，此通信一般为：跨模块的函数调用，模块间的变量访问

如A文件中调用B文件中的函数，编译A文件时，编译器并不知道B中此函数的地址，所以编译时无法得知，此时就需要在链接期间，由链接器负责将对应的地址填入，就像是模块拼接一样。



静态链接时链接过程主要包括，地址和空间分配（Address and Storage Allocation）、符号决议（Symbol Resolution）、重定位（Relocation）等。

> 个人理解：如A文件中调用B文件中的func函数，那么链接时需要将B文件的func符号（编译器会对函数生成独一的符号）和其分配的地址绑定，即为符号决议（动态链接时一般叫绑定Bounding），然后在A文件的调用位置将此符号对应的正确地址填入，即重定位；但是地址和空间分配不太理解，不应该在编译期间各自负责各自的地址分配吗，其他模块中使用类似占位符，链接填入即可啊，为什么链接期间还要分配地址和空间

PS：符号Symbol这一概念的引入是在汇编中，用符号来代替难以记忆的地址，也就是说符号即地址，了解这一历史，那么对于符号的理解将会由很大益处。



> 在后续学习了静态链接后对于虚拟内存空间分配，重定位等有了更直观的认识，但是也进入了误区：
>
> 认为链接是针对有一个或多个专门的目标文件，但是不要忘了，目标文件也是由.c文件编译而来，链接实际上是将各个.c模块链接在一起，而不是.o文件，所以一个大型项目中存在多个.c文件，VS一点运行，先编译得到各自的目标文件，然后将这些目标文件链接再一起，这一过程是连续的，而不是相互隔离！！



#### 第三章 目标文件有什么（.o文件 Object File）

##### 可执行文件格式

Windows下的可执行文件格式为PE（Portable Executable），Linux下的格式为ELF（Executable Linkable Format），两者均属于COFF（Common File Format）格式的变种

目标文件（.obj / .o）的格式和可执行文件（.exe / a.out ....）格式几乎一样，所以视为一类；同时动态（.dll / .so）和静态链接库（.lib / .a）以及核心转储文件（Core Dump File）均属于可执行文件格式



Linux下的ELF格式文件种类有可重定位文件、可执行文件、共享目标文件、核心转储文件

| ELF文件类型 | 实例                   |
| ------- | -------------------- |
| 可重定位文件1 | .o .obj 即目标文件以及静态链接库 |
| 可执行文件   | .exe /bin/bash       |
| 共享目标文件  | .dll .so             |
| 核心转储文件  | core dump            |



> 个人理解：代码段中存放着指令，而这些指令中有关数据或者函数调用的地方均指向最终存放这些（数据\函数）的地址，而且代码段中不会有数据的二次定义，数据是被存放在数据段或者bss段或者rodata等地方



#### 第四章 静态链接

之前提到，链接器的主要功能包含地址和空间分配，地址与空间代表两种意义：

1、在可执行文件中的空间；

2、在装载后的虚拟地址中的虚拟地址空间

像BSS段只会分配虚拟地址空间，不会有可执行文件空间



##### 符号解析和重定位  

链接器普遍采用两步链接的方法，第一步为空间与地址的分配，第二步为符号解析和重定位：

空间与地址的分配，此处主要指虚拟地址空间的分配，各目标文件经过相似段合并后将各自的段表整合，并且分配虚拟地址空间；Linux中ELF可执行文件默认从地址0x0804800开始分配

符号解析和重定位，原本目标文件中如果存在外部引用，编译器会填充一个“暂时分配值”，在链接时，由于各目标文件已经完成整合，可以根据全局的符号表，为此位置填充最终的虚拟地址，此类填充分为两种，绝对寻址修正和相对寻址定位（每个被修正的位置均为32位），绝对修正指填充的虚拟地址即该符号的实际存放位置，而相对修正指填入的虚拟地址为符号距离修正地址的**距离差**；如call指令后面的4字节 A 代表：call指令的下一个指令所在位置 + A即为call指令实际调用的符号位置。

上述引用了外部符号的地址均需要重定位，称为重定向入口（Relocation Entry），重定位入口的偏移量（Offset）即为该入口在要被重定位的段中第一个字节相对于段起始的偏移





##### COMMON块

最初设计为，在没有动态分配内存的前提下，每个变量需要申明自身需要的临时空间大小，此空间即为COMMON块；C++中如果有多个同名弱符号，最终会选择空间占用最大的那个符号，但是如果在编译时提前分配虚拟空间大小，链接时可能会有多个空间占用（或者说最终的空间占用未知），但最终只选取一个；所以分配空间的职责落在链接器身上，负责在多个同名弱符号中选择空间最大的一个。也因此，COMMON类型的符号在编译后不会出现在BSS段（即使是未初始化的全局变量），但链接时，链接器已经知晓所有的输入目标文件，故最终大小已确定，又会为其在BSS段分配空间。

而究其本质，是因为编译器和链接器不支持符号类型，导致多个同名弱符号出现。如double和int类型的变量其最终符号名一样。

未初始化的全局变量（弱符号）属于COMMON类型变量；而未初始化的局部静态变量不是





##### C++相关问题

###### 重复代码消除

由于模板Templates、虚函数表、内联函数等原因，C++代码中会有很多的重复代码，如果无视这些重复代码，将会有大量的空间浪费，同时也会导致指令运行效率较低（因为CPU会对指令和数据缓存，如果同一份指令有大量的副本，将会导致cache命中率降低，我的理解为这些副本虽然相同但是各自不知道各自重复，所以相当于浪费了cache的空间）

目前的主流做法为：将每个模板的实例代码作为一个单独的段，如此同名的段就是相同的代码，链接时就可以将这些同名段只保留一个；反观之前的做法，模板的代码会混入text段，无法区分是否重复；

对于内联和虚函数表的处理也与之相似，类如果使用虚函数，编译器将会为用到此类的多个编译单元生成虚函数表，导致重复，所以为每个虚函数表单独建立段。

GCC中将此类的段称为Link Once，段命名为.gnu.linkonce.name，Visual C++中此类段称为COMDAT

不过由于各编译单元可能采用了不同的优化选项或者编译器版本，所以此类重复代码消除仍然会产生警告信息，告知可能存在的风险。

###### 函数级别链接 Functional-Level Linking

在项目非常庞大时，一个目标文件就会包含很多函数和变量，如果仅仅使用某个函数或者变量，也需要将整个目标文件链接起来，这就导致包含了大量无用的函数，链接输出文件也会很臃肿，所以编译器提供函数级别链接（ Functional-Level Linking， /Gy，GCC中为 -ffunction-sections, --fdata-sections），即允许将各个函数作为单独的段编译，当链接器需要某个函数时，将该函数的段合并入输出文件，其它无用的函数段直接丢弃。

此做法的优点为减少了文件的臃肿，但是代价为编译和链接时间变长，因为需要检查各个函数的依赖关系，从而生成独自的段，而且段数量增加也增加了重定位的复杂性。

###### 全局对象的构造和析构

全局对象的构造与析构需要在`main`函数执行之前和之后完成；而Linux下C++程序的执行入口为`_start`，此函数来自于Linux的系统运行库Glibc，此函数即为程序的初始化入口，我们的程序在完成和Glibc的链接后，会在`_start`执行完一些初始化工作后才会调用main函数执行。

基于以上原因，ELF文件中包含两个特殊段，`.ini`段和`.fini`段，分别完成main函数执行前的初始化和执行后的收尾工作

###### C++和ABI

ABI Application Binary Interface

二进制兼容问题：如果两个目标文件来自于不同的编译器版本或者不同编译器，能否将两个目标文件链接起来？那么链接器至少需要认识两个目标文件的文件格式（ELF/PE），对不同名称但同类的段做出相同处理等等。

所以两个编译器编译出的目标文件若要链接起来，需要采用相同的目标文件格式、拥有相同的符号修饰标准、变量的内存分布方式相同、函数调用方式相同等等，其中的符号修饰标准、量的内存分布方式、函数调用方式等与可执行代码的二进制兼容性相关的内容称之为ABI

和API Application Programming Interface相似，ABI也是接口，但ABI是二进制级别的接口，API仅仅是源码级别的接口。影响ABI的因素很多，包含硬件、编程语言、编译器、链接器和操作系统等多方面。

C++因引入继承、虚函数、指向成员函数的指针、模板等导致二进制兼容性较于C语言更难以达到。

###### 静态库链接

使用静态库时（如libc.a，printf等函数就在其中），通常为操作系统所提供的函数集合，或者说一组目标文件的集合，就如Functional Level Linking中所述，这些函数通常一个函数即为一个目标文件，然后通过ar压缩软件，将这些目标文件压缩打包成一个库文件libc.a，当我们直接gcc编译时，链接器会帮我们在libc.a静态库中寻找所需的目标文件（以及这个目标文件所依赖的其他目标文件）并链接在一起。

理论上来讲，如果我们手动将所需的目标文件链接起来，也是可以直接使用的，但是现实往往更加复杂，链接时不仅仅会链接所需的目标文件，还需要更多的辅助目标文件。



###### 链接过程控制

链接器ld在使用过程中，用户可以人为的控制链接的过程，方法有三种：

1、在ld命令行中加入参数，如ld -e -o等

2、将链接指令存放在目标文件中，如VISUAL C++编译器会把链接参数存放在PE目标文件的`.drectve`段中以传递参数

3、使用链接脚本，很多特殊的链接过程常常使用此方式，而且之前提到的一些特殊变量也是在链接脚本中定义，此部分内容我仅作为知识点扩充，略读书中教程，未深入探究



###### BFD库

因编译链接过程常常于硬件和软件相关，跨平台的编译链接器实现需要考虑大量区分点，所以目前的解决方案为使用BFD库将需要处理的目标文件抽象成统一的模型，如果需要新增新的目标文件格式，只需要在BFD库中添加一种格式，而大量的系统和硬件不同由BFD库面对，而无需编译器和链接器直接面对，从而隔离了硬件或系统异常。

个人理解：相当于把适配问题下放到BFD库，从而减缓编译器和链接器的适配难度



##### 遇到的问题

###### 问题1

编译```gcc -c a.c b.c```得到a和b的对象文件，然后手动链接`ld a.o b.o -e main -o ab`报错

`undefined reference __stack_chk_fail`

错误分析：最初认为是因为a.c文件中使用了未声明的swap函数导致，但是链接时实际上将两者链接在一起，不该有此问题；

经查询后发现是因为gcc编译器默认会使用`__stack_chk_fail`进行栈检查，而ld手动链接时，未能链接到`__stack_chk_fail`库函数，导致错误，这也和报错中的描述对应。

所以解决的方法在于编译时取消默认的栈检查，即`gcc -fno_stack_protector -c a.c b.c`，然后手动链接即可



###### 问题2 P125

在书中以内联汇编的形式执行Hello World程序从而摆脱库函数的依赖，但是在ubuntu 20环境下编译失败，报错为mov 报错，经查询发现书中的程序为32位程序，而ubuntu 20是64位环境，所以究其本质此报错属于ABI问题。64位程序下`typedef  long    size_t;`也就是说占8字节，而32位系统中此类型只占4字节。[(23条消息) X64下的内联汇编避坑之“mov报错？”_＇弦歌知雅意的博客-CSDN博客](https://blog.csdn.net/qq_44413572/article/details/113887993?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_antiscanv2&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1.pc_relevant_antiscanv2)

而书中为摆脱库函数依赖，直接使用的是write的汇编，其参数中包含char* 和 size_t用于分别表示要打印的字符和字符长度，如果仍然如书中所言使用`movl`就会报错，此二参数需要修改为`movq`，修改后报错仍然存在，此时报错为无movq指令！查询后在一个评论区发现，64位系统下继续使用eax寄存器是非法的，如果希望继续使用堆栈应该使用rax，这是和eax相对应的64位版本，[关于汇编：C使用汇编：操作数类型不匹配进行推送 | 码农家园 (codenong.com)](https://www.codenong.com/21245245/)修改后编译通过，后续链接也无错误。

此外，除以上方法外，还有一种就是在64位系统中继续以32位编译程序，gcc时加上参数，`-m32`，但是后续链接时会报错`undefined reference to _GLOBAL_OFFSET_TABLE_`，所以还需要加上参数，`-fno-pie`

[(23条消息) 《程序员的自我修养》TinyHelloWorld编译方法_Whu-MT的博客-CSDN博客](https://blog.csdn.net/MT1232/article/details/102478022?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0-102478022-blog-123957197.pc_relevant_multi_platform_featuressortv2removedup&spm=1001.2101.3001.4242.1&utm_relevant_index=3)

```c++
char* 8
size_t 8
```

![链接过程控制中遇到的问题](..\图片\程序员的自我修养-images\链接过程控制中遇到的问题.jpg)








PS：透明即不可见

未初始化的全局变量是COMMON类型，是弱符号；

而如果一个未初始化的全局变量不是COMMON类型，将视为强符号





#### 第六章 可执行文件的装载与进程

可执行文件最终要放入内存中执行，此过程即为装载。

进程是最小的资源分配单位，每个进程都有自己独立的虚拟地址空间，该地址空间的大小由硬件平台决定，或者说由CPU的位数决定，如32位理论最大寻址为$2^{32}-1（4GB）$，64位硬件平台下寻址为$2^{64}-1$，但是此空间不是进程全部占有，操作系统会占用其中一部分，如32位Linux下总共4GB虚拟地址空间，OS会占用1GB，用户可使用3GB，实际使用中3GB中还会分出一部分预留给其他用途；而Windows系统下OS会占用2GB，不过此值可修改。

但是以上的虚拟地址空间仅仅为进程可访问的最大寻址范围，而实际的物理内存可寻址范围是可能超出虚拟地址空间范围的，如32位硬件下虚拟地址空间可寻址4GB，但实际上1995年Intel CPU扩充了地址线数量，达到36位地址线从而使得物理内存寻址范围达到$0 \sim  2^{36}-1$，于是Intel修改了页映射方式，从而可以访问更大的物理内存，此方式即为PAE（Physical Address Extension）；而如果用户侧需要访问超出4GB的内存空间，那么需要使用系统调用--内存映射，如Linux下的`mmap()`，Windows下的`MapViewOfFile`

##### 装载方式

 装载方式和操作系统层的内存管理层层相关，从静态装入到动态装入，静态装入是将整个可执行文件直接载入到内存，但内存利用率低，而且很可能内存不足以全部载入；所以动态装入出现，将需要的模块装入内存，不用就暂时不装入，典型的动态装入有覆盖装入（Overlay）和页映射（Paging）。

###### Overlay 覆盖装入

在虚拟存储出现前较常使用，目前几乎被淘汰。Overlay要求程序员自己控制内存装入，且编写代码时手动将程序分割为若干块，然后使用辅助代码管理这些模块何时装入，何时替换出内存。此辅助代码即为覆盖管理器（Overlay Manager），所以需要分析各模块之间的调用依赖关系，程序员会将此调用依赖关系组织成为树状结构，以main函数为树根，此方式一般遵循两原则：1、调用路径上的所有模块都需要载入到内存；2、不允许跨树间的调用，如果某模块两树均调用，可以将此模块并入main模块

###### Paging 页映射

个人理解，页映射即为OS的请求分页调度算法，是将覆盖装入优化为更加通用的版本，内存调度单位为页page，而且覆盖管理器交由操作系统实现完成，换入换出有对应的置换算法，触发通过缺页中断实现。

##### 操作系统层面的装载

常见的场景为：分配一个新进程，然后装载相应的可执行文件并执行；如在bash中执行某项可执行文件

为完成以上任务，需要做的事项如下：

1、创建一个独立的虚拟内存空间

`fork()`系统调用会新建一个进程，并创建该进程的虚拟内存空间，但实际上所谓的虚拟内存空间即为物理内存和虚拟内存中各页之间通过页映射函数完成的映射关系，创建虚拟内存空间不是创建空间，而是创建映射函数所需的相应数据结构，如i386的linux下仅仅是分配了一个页目录，并没有做实际的映射，**实际映射要等到页错误发生时再设置，而页错误在程序执行时才会出现**

2、读取可执行文件头，并且建立虚拟内存空间和可执行文件的映射关系

`exec()`系统调用会执行你所传入的可执行文件，而其执行过程中 首先会检查可执行文件的前128字节，通过其中的Magic Number核对其文件类型（因为可运行文件不只有elf，还有bash、python脚本等），然后建立起虚拟内存空间和可执行文件之间的映射关系，同样这种映射关系也只是保存在操作系统内部的一个数据结构中，如**Linux系统中将进程虚拟内存空间中的一个段称为VMA**（Virtual Memory Area），Windows将其称为Virtual Section。最简单的方式是elf中的一个段即为一个VMA，不过如此会产生大量内部碎片，所以会根据段的权限重新合并VMA。

> 之所以需要建立虚拟内存空间和可执行文件间的映射关系是因为，通过第一步已经完成了虚拟空间和物理空间的映射，即程序访问某个地址，可以通过地址映射找到对应的实际内存位置，但是缺页中断产生时，首先要做的是将硬盘中的文件换入到内存中，那么程序仅知晓虚拟内存地址，OS需要将这块虚拟内存地址对应的文件找到并换入，所以需要建立虚拟内存和文件的映射

3、将CPU指令寄存器设置成可执行入口

即将可执行的入口存入指令寄存器中，以便程序执行，这个同样是`exec()`系统调用完成，如果是静态链接的elf文件，那么入口即为elf文件头中的e-entry，动态链接的elf，则此值应该为动态链接器

完成上述步骤后elf可执行文件装载完毕，而且以上描述实际被封装在fork和exec两个系统调用中，将大量的实现细节屏蔽；

而且完成了以上步骤之后，其实可执行文件的指令和数据并没有被装入物理内存，仅仅完成了各内存空间以及文件的映射，当CPU根据执行入口开始执行时，会发现页空，从而触发页中断，于是产生系统调用，OS会根据第二步中的映射关系找到对应的可执行文件偏移量，并在映射的物理内存空间中分配实际物理内存，然后将程序控制权交给进程，从而继续执行下去。



##### 进程虚拟空间分布

最简单的虚拟地址空间分布是ELF中的一个段即为一个VMA，不同VMA分布在不同的页page，如.text，.data各自一个VMA，但是有些段所占字节很小，因为页对齐的原因，这样一个VMA就会占用一整个页page，造成大量的内部碎片；而对于操作系统而言不关心段内部的内容，不同段之间仅仅在于权限不同，所以可以根据不同的权限组合将段整合在一起，同权限的段作为同一个VMA，从而减少内存浪费。此类区分基本为三种：

代码段为代表的可读可执行段；数据段和BSS段为代表的可读可写段；只读数据段为代表的只读段

而这种合并后的段，被称为Segment，而之前提到的ELF中的段称为Section；**其实两者是对ELF文件的两种视角View，从装载角度即为Segment，从链接角度即为Section**。描述Segment的数据结构是程序头（Program Header）

###### 堆和栈

每个Segment对应一个VMA，而堆和栈也会有各自相应的VMA，如下所示heap和stack有对应的虚拟空间分布，最后的vdso其位置位于内核空间，进程可以通过访问这个VMA来和内核通信。

后三个段的主设备号和次设备号、节点号均为0，表示没有映射到文件中，此类VMA称为匿名虚拟内存区域

```
$ ./SectionMapping.elf &
[1] 21963
$ cat /proc/21963/maps
08048000-080b9000 r-xp 00000000 08:01 2801887    ./SectionMapping.elf
080b9000-080bb000 rwxp 00070000 08:01 2801887    ./SectionMapping.elf
080bb000-080de000 rwxp 080bb000 00:00 0          [heap]
bf7ec000-bf802000 rw-p bf7ec000 00:00 0          [stack]
ffffe000-fffff000 r-xp 00000000 00:00 0          [vdso]

第一列是VMA的地址范围；
第二列是VMA的权限，“r”表示可读，“w”表示可写，“x”表示可执行，“p”表示私有（COW, Copy on Write），“s”表示共享。
第三列是偏移，表示VMA对应的Segment在映像文件中的偏移；
第四列表示映像文件所在设备的主设备号和次设备号；
第五列表示映像文件的节点号。最后一列是映像文件的路径。
```

堆能够分配的总内存大小受到操作系统的版本、程序本身、用到的动态库/共享库数量、大小、栈数量大小等关联。

###### 段地址对齐

可执行文件最终要被操作系统装载运行，而此过程通过虚拟内存的映射机制完成，映射过程中最小单位是页，所以Segment的对齐以页为单位，如32位系统中一般页大小为4096字节，所以虚拟地址空间的起始地址必须是4096的整数倍。但是如此之下，相邻两个VMA之间仍然会产生内部碎片

![可执行段未合并](..\图片\程序员的自我修养-images\可执行段未合并.png)

所以优化方案为：物理内存中VMA之间不再分离，而是连续存放，即相邻段之间共享同一个**物理页**，但是在虚拟内存中会映射两次，分别映射出各自段的部分，另外ELF文件头也会一起合并；如下图所示。因为虚拟内存空间中映射两次的缘故，所以有些VMA的起始位置不是上一个VMA的结束位置加上偏移量，而是另开一页再加上一个VMA在页中部分。

![可执行段合并](F:\Markdown\研一上\图片\程序员的自我修养-images\可执行段合并.png)

###### 进程栈初始化

进程栈在初始化时会在栈顶初始化参数数量、对应参数指针（即为main函数的argc和argv）以及指向环境变量字符串的指针；进程启动后，程序库会把这些参数信息传递给main函数

##### Linux内核装载ELF过程

本质和之前OS层面的装载相同，通过fork和exec函数的封装完成进程虚拟内存空间创建，读取可执行文件前128字节，检查文件类型`do_exec()`，然后根据类型搜索合适的装载处理过程；装载时会根据程序头描述完成ELF文件到虚拟内存空间的映射，并初始化进程环境，最后将系统调用的返回地址修改为可执行文件的入口；等到从核心态转至用户态，此时内核的寄存器（具体待查）中已保存有可执行文件入口，可以直接执行。

由此也可以看出，以上过程中没有实际的内存映射，如映射多大内存等，仅仅修改了操作系统的数据结构（文件到虚内映射），创建映射函数所需的数据结构（虚内和物内的映射），一切分配内存等仍由缺页中断驱动，这也和操作系统中所学到的一致。

````c++
int exec()
{
  do_exec()
  {
    search_binary_handle()
    {
      load_elf_binary()//elf可执行文件装载
    }
  }
}

````



##### 遇到的问题

操作系统层面的装载中提到CPU执行时发现页空，从而触发页中断 ；那么CPU如何发现页空？检查物理空间？检查虚拟空间？虚拟空间中设置标志位？需要检查下操作系统的内存管理机制。



#### 第七章 动态链接

##### 为什么要动态链接

静态链接的不足/缺点 ：

1、**内存和磁盘占用大**，不是因为本身占用大，而是会存在大量重复的内存占用，如A、B、C三个程序同时需要目标文件D，那么目标文件D将会在三个程序链接时放入各自的可执行文件中，占用虚拟内存空间，即D会有三个的副本

2、**模块更新困难**（程序开发和发布）；如果某个目标文件LIB.o更新，那么使用LIB的程序如果要更新就需要和最新的LIB.o重新链接才可以使用；如某程序有20个模块，每个模块1M，那么每次更新任一模块都会导致20M文件的重新链接，用户也需要重新获取这20M的程序，尤其在网络更新程序时，程序每一个微小改动都会导致整个程序的全部下载



解决方案：将程序中各个模块解耦，各自相互分割、独立，即对于目标文件的链接推迟，等到需要使用该模块时再链接（运行时链接），防止每次都需要重新链接，且如果多个程序使用同一个模块，此模块将可以共享，进而减少内存占用；

而此模式涉及运行时链接和装载问题，需要OS级别的支持，故Windows和Linux均支持此模式，Windows下动态链接文件称为动态链接库（Dynamical Linking Library，dll），Linux下称为动态共享对象（Dynamical Shared Objects，so）

> 个人理解：动态链接下相当于将原本目标文件管理权上移，交由OS管理，不再是每个程序独立拥有此文件，进而实现了目标文件的共享



##### 简单的动态链接例子

```shell
gcc -shared -fPIC -o lib.so lib.c
#shared 动态链接
#fPIC 地址无关代码
```

静态链接中，装载时只需要关心可执行文件，因为所有的“辅助”目标文件已经整合进入可执行文件，所以只需要映射可执行文件；但是动态文件中，除了装载可执行文件，所依赖的共享目标文件同样需要被装载。

###### 固定装载地址 OR (装载时重定位 & 地址无关代码)

* 动态链接下的装载，一种考虑为像静态链接一样，链接的同时即分配虚拟地址，但是动态链接中模块是会被多个程序共享的，如此分配下会产生地址冲突问。如，把0x1000到0x2000分配给模块A，0x2000到0x3000分配给模块B，而某程序不需要模块A，为提高内存使用率将此地址分配给模块C，那么模块A和C的目标地址就会产生冲突，之后的程序都不能同时使用A和C了。并且真实系统内运行的程序数量很多，为提高内存利用率，冲突发生概率不低。

此种方式在早期的系统中被采用，并且称为**静态共享库（Static Shared Library）**，故为解决模块地址固定的问题，提出了**装载时重定位（Load Time Relocation）**的方法（Windows下称为基址重置Rebasing）。

* 装载时重定位思路如下：链接时不在对绝对地址做重定位（静态链接），把这一步延迟到装载时完成。当装载地址确定，即目标地址确定，再对程序中所有的绝对地址做重定位。

但是，不要忘记动态链接的初衷--共享性，共享目标文件是需要被多个程序同时使用的，如果此共享目标文件在第一个程序运行时被装载映射到虚拟地址空间，确定最终地址，那么它的代码指令会被修改，从而无法实现共享指令。

> 个人理解：共享目标文件在第一个程序运行时被装载，并确定最终地址，此共享模块的代码指令中就有可能存在模块间的调用或者数据访问，此时代码指令中就可能带有此类的绝对地址（参考静态链接时的两种重定位）；此时第二个程序运行时分配的地址显然不会和第一个相同，那么如果直接使用就有可能修改第一个程序的数据段部分。

* 所以出于提高共享性的考虑，GCC提供了-fPIC参数用于动态链接，此参数表明采用**地址无关代码（Position-independent Code， PIC）**技术。



> 核心思路，无论是模块内还是模块间，无论是函数调用/跳转还是数据访问，不再使用绝对地址，全部转为相对地址，间接访问。这样当然会减缓运行速度，毕竟多了一个中间层
>
> 另：动态链接时，**共享目标文件的数据段不共享，各进程拥有各自的副本**，got等表也不共享，got可视为戴数据表的一部分；仅共享代码段。

待补充：四种模块、模块间数据访问和函数调用



为了实现共享性，所以提出了装载时重定位，单纯的装载时重定位运行速度会更快，但是会使得代码段无法共享，所以为了将代码段共享，所以提出了地址无关代码，将代码段中的绝对地址转换为相对或者增加中间层（GOT Global Offset Table）；

###### 延迟绑定

解决以上问题后，基本问题已经解决，但是程序执行前会将共享对象中的所有函数都装载并重定位，而有些函数可能永远也不会被使用，所以提出了延迟绑定（Lazy Binding），基本思路为在函数第一次被使用时才进行绑定（符号查找、重定位等），ELF中使用了PLT（Procedure Linkage Table）的方法，即在原有GOT表之前再增加一个间接层PLT（我的理解是第一次调用时会通过PLT方法将GOT表中的对应符号重定位，则之后的调用中不会在经过PLT）

###### 动态链接相关结构

* 实际使用中GOT被拆分为`.got`和 `.got.plt`，前者专用于全局变量引用的地址，后者用于保存外部函数的引用地址；
* 动态链接的重定位表分别为`.rel.dyn`和`.rel.plt`，前者是对数据引用的修正，即got以及数据段，后者则是对函数引用的修正，即`.got.plt`

实际使用中由于存在全局符号介入**Global Symbol Interpose**，（即如果两个共享对象中定义了同名函数（符号名也相同），那么根据装载顺序，此函数定义以先装载的函数为准，即后装载的函数被覆盖）；所以**模块内的函数调用也不能直接使用相对地址访问，而是使用GOT方式**；如函数foo中调用bar，而另一共享模块中定义了bar并覆盖了foo中调用的bar版本，所以此模块内调用也需要进行重定位，需要GOT帮助

* `.dynamic`表相当于共享对象的文件头，保存有动态链接**符号表**、动态链接**重定位表地址**，动态链接重定位表入口数量，**依赖的共享对象文件名**，依赖的共享对象**搜索路径**等信息

###### 动态链接后的执行（书中为动态链接的步骤和实现）

个人理解：使用动态链接的共享对象链接得到可执行文件时，只是简单的将需要的共享对象等信息记录（写入`.dynamic`？？），真正的重定位要在装载时

那么在执行一个使用了动态链接的可执行文件时，首先，和静态链接中相似，通过fork和exec函数开辟新的进程空间，并找到对应的处理程序，完成堆栈初始化后，系统将程序控制权交由动态链接器（在静态链接中控制权交由ELF文件头中所表明的程序入口e_entry）；动态链接器获取控制权后会首先完成自举，然后将可执行文件和链接器自身的符号表合并到一个符号表（只是符号表，没有重定位表）中，称之为**全局符号表 Global Symbol Table**，紧接着链接器寻找可执行文件所依赖的共享对象，（由可执行文件的.dynamic段可知所依赖的对象），并将所有所需共享文件的名字放入装载集合中，从中取出一个、找到并打开文件，读取其ELF文件头和`.dynamic`段，合并符号表到全局符号表中，然后将其代码段和数据段（~~代码段应该是第一次会映射到进程空间吧？之后共享？~~此处仅为映射到进程空间，类似于之前静态链接所提到的物理内存段会映射两次到进程空间，共享只需要做好内存到进程空间的映射关系即可）映射到进程空间，若此ELF共享对象还依赖于其他共享对象，则将所依赖的共享对象一并加入到装载集合，如此依照一定的依赖顺序（**类似图的遍历，所以可以广度或者深度遍历**）将所有的共享对象全部装载。

完成上面的步骤之后，动态链接器已经拥有一个覆盖所有共享对象、可执行文件和动态链接器本身的全局符号表，那么链接器再遍历可执行文件和共享对象的重定位表，将各自的GOT\PLT表中需要重定位的位置修正即可。

此时如果共享对象有`.init`段，动态链接器会执行此段中的代码，以完成如全局/静态对象的构造，相应的在程序结束时，如果有`.finit`段，也会去执行相关代码，以完成全局/静态对象的析构。

但是如果可执行文件有`.init / .finit`不是由动态链接器负责执行，而是交由程序初始化部分代码完成。

> 动态链接器本身是一个特殊的共享对象 + 可执行文件，而共享对象的重定位等工作是由动态链接器完成的，所以动态链接器本身的重定位就需要很谨慎，没有人可以帮助它完成重定位，导致动态链接器**1、不能依赖任何的共享对象**，且**2、需要在一段不使用全局和静态变量甚至函数的程序中完成自身的重定位工作**，此段程序称为**自举**。
>
> 动态链接器自举代码首先找到自己的GOT表，而GOT的第一个入口保存的即为`.dynamic`的偏移地址，通过`.dynamic`信息找到动态链接器本身的重定位表和符号表，然后完成自身的重定位，修改对应的GOT表项。









###### 遇到的问题

1、如果存在程序A、B，同时运行并共享同一个动态模块C，根据书中所言，C的数据段在各程序中相互独立，而代码段共享，那么C的代码段是否还被装载到各个程序中，是第一个运行的程序，比如A先运行，A同时装载了独立的C的数据段和共享的代码段，然后B运行，此时B对于C的代码段装载吗？？？

如果装载，那么动态链接的共享性如何体现？？因为相当于每个程序对于共享模块都加载到内存中，在内存使用方面就和静态链接无异！即没有增加`-fPIC`参数

>  个人理解：
>
>  看完动态链接器装载部分，我认为代码段和数据段在进程的虚拟地址空间里是都有的，但是在内存里只有一个，即类似静态链接中为节约内存空间，Segment之间连续存放，不再分页，但是映射到进程地址空间时映射多次，所以只需要管理好内存到地址空间的映射就可以
>
>  当然数据段在内存也是多份，无法共享！



2、阅读动态链接要时刻分清楚同模块、模块间、模块和可执行文件区分（PS：共享模块和可执行文件不一样！！！）

3、疑问：动态链接器自举过程中如何找到自己的GOT，如果能找到GOT，为什么不能直接找到`.dynamc`，并借此找到符号和重定位表

4、书中提到动态链接器是特殊的共享对象，需要自举完成重定位，且过程中避免使用全局变量甚至函数，但之后又提到动态链接器是静态链接的，那么根据之前章节所述，静态链接的文件重定位工作在链接时完成，根本不需要再做所谓自举？？？

5、使用动态链接，如共享对象C.dll，而本程序本身是由多个文件组成，即编译会形成多个目标文件，那么本程序内部的这些目标文件是如何链接的？动态？静态？

个人觉得是~~静态~~，如果是动态，按照之前的理解，动态链接的所谓链接部分基本不做什么，**真正的链接发生在执行之前（运行时），P200**，那么模块内部多个目标文件之间无法发现是否存在符号重定义或者未定义，执行之前就需要对模块内部也作一次类似模块间的重定位，这一点首先书中没有明说，其次书中P191 关于模块内部和模块外部，提到符号可能被定义在同一共享对象的其他目标文件中，所以无法明确符号位于模块内还是外，也就是说符号定义在同一共享对象的其他目标文件中视为模块内部。额，怎么感觉也是动态。。。。



PS：可以尝试下gcc链接时不加共享对象参数，其生成的可执行文件dynamic段会不会缺失依赖的共享对象名称；如果报错说明动态链接的链接部分并不是完全什么都不做

#### 第八章 Linux共享库的组织

##### 共享对象和共享库

首先两者基本等同，因为库作者经常采用动态库方式提供库，所以共享库即共享对象

##### 共享库版本命名规则

`ldxxx.so.x.y.z`

其中ld为固定前缀，xxx为库名称，xyz分别代表主版本、次版本、发布版本号

主版本号代表库重大升级，不同主版本号库之间不兼容；

次版本号代表增量升级，即新增了一些符号接口，主版本号相同情况下，次版本向下兼容；

发布版本号代表对于库的错误修正、性能修改等，不涉及新增接口

##### SO-NAME

`.dynamic`段中的所依赖的库名称中存放的即为**SO-NAME**，本质上即为ldxxx.so.x，只有主版本号；

Linux系统中，系统为每个共享库在其所在目录创建一个和“SO-NAME”相同的且指向它真实存放地的软链接，系统中安装或者更新共享库时，运行`ldconfig`程序，就会自动更新所有的软链接或者创建对应软链接，保证指向**最新版本的共享库**

##### 符号版本

在仅采用版本号和SO-NAME的情况下，会存在**次版本交叉问题（Minor-revision Rendezvous Problem）**，如某程序运行依赖于版本2.7.3，但是SO-NAME指向的系统中存在的最新版本为2.6.1，两者主版本一致，次版本不同，如果此程序中使用的某个符号依赖于2.7版本后新加入的接口，那么直接运行会有程序运行错误风险；而如果程序实际使用的符号没有来自于2.7版本的新接口，那么运行正常。

所以Solaris系统中首先引入了**符号版本机制**：即随着共享库的升级，各个符号具有着其对应的版本，或者说一些符号集合，集合名称即符号版本，如VERS_1.2。而这些集合的定义以及所包含的符号通过**符号版本脚本文件**来指定，并且在链接时使用，此文件指定了符号和集合之间的关系，以及集合之间的依赖关系。并且通过此文件可以将一些全局符号改为局部符号，从而使得外部的应用程序或其他共享库无法访问这些符号，实现符号的**范围机制**，因为共享库作者不想使用者访问到这些仅限内部使用的符号。

> 感觉有点类似于每个次版本的符号集合，SO-NAME中只有主版本信息，此机制相当于补充

**编译和链接程序时，链接器会在最终输出文件中记录所用到的版本符号集合**，那么面对次版本交叉问题，如程序依赖于VERS_2.7版本的符号，而系统中的共享库中的符号版本是VERS_2.6，那么直接报错，而不是像只依赖SO-NAME一样存在运行中出错风险。

```C++
SUNW_1.2//符号集合名
{
  global://全局符号
  pop;
  push;
  
  local://局部符号
  *;
}

// 发生版本升级后，如新增了符号
SUNW_1.3//新符号集合名
{
  global:
  swap;
}SUNW_1.2;//1.3会继承原有的1.2版本符号


```



GCC下新增了同一个共享库中的一个符号名可以同时存在于不同版本的符号集合（或者说 一个符号可以同时属于多个版本），即链接层面某种形式的符号重载，如不同定义的printf符号在VERS_1.1和VERS_1.2中同时存在，旧版本的程序链接旧版的printf，新版的链接到新版的printf。P239

个人理解：不同版本下的printf的接口不同，相当于修改了接口，无法继续兼容，Solaris中需要新增符号，且升级主版本号，导致主版本因小变动而修改；而Linux下就可以给printf的不同实现赋以不同的符号版本号，链接时决定具体链接到哪个定义处。

```C++
asm(".symver old_printf(), printf@VERS_1.1")//gcc允许使用.symver汇编宏指令来指定符号版本
asm(".symver new_printf(), printf@VERS_1.2")
  
int old_printf(){...}
int new_printf(){...}
// 老版本会链接到old_printf， 新版本符号会链接到new_printf
```



##### 共享库系统路径

Linux遵循FHS（File Hierarchy Standard）标准，标准中规定了系统文件如何存放，包含各目录的结构、组织和作用。FHS规定系统中主要有三个主要存放共享库的位置：

1、/lib，主要存放系统中最关键和基础的共享库，如动态链接器、C语言运行库、数学库等

2、/usr/lib，主要存放系统相关，但非关键性的共享库，如开发时会用到的动态库和静态库等

3、/usr/local/lib，主要存放系统无关的共享库，GNU规定第三方程序的库默认安装在此目录下，其他还有如python解释器等



`.dynamic`中的`DT_NEED`中存放可执行文件所需的共享库，此值可以是共享库的绝对路径，也可以是相对路径，如果是相对路径，动态链接器就在系统路径/lib, /usr/lib, /etc/ld.so.conf配置文件指定的路径下搜索。

> 因为遍历共享库目录比较费时，所以ldconfig程序（建立SO-NAME的程序）还会将所有的SO-NAME集中存放到/etc/ld.so.cache中，而此cache文件更适合搜索，所以遍历更快；如果找不到才会去/lib, /usr/lib, /etc/ld.so.conf配置文件指定的路径下搜索

###### 搜索过程

搜索路径：

LD_LIBRARY_PATH指定的路径 ---> -L参数指定的路径 --->  SO-NAME缓存 /etc/ld.so.cache --- > 系统默认路径(/lib, /usr/lib) --- > /etc/ld.so.conf配置中指定的路径

##### 环境变量

###### LD_LIBRARY_PATH

此环境变量中可以设置多个共享库所搜路径，以分号隔开，作用和`gcc -L xxx`类似

###### LD_PRELOAD

预装载环境变量，在此变量中指定的共享库会在动态库按照其规则装载共享库之前装载，且无论程序是否依赖于它；

**作用：**由于全局符号介入（先装载的同名符号生效，后装载的同名符号被重载），利用此环境变量指定的共享库或者目标文件中的全局符号会覆盖后装载的同名全局符号，从而实现替换标准C库中的某些函数而不影响其他函数。

/etc/ld.so.preload文件作用和此环境变量相同

###### LD_DEBUG

此变量可以打开动态链接器的调试功能



##### Windows下的动态链接（简略）

Windows下使用DLL作为共享对象，不同于**Linux下的全局函数和变量默认可以被其他模块使用，使用其他共享对象的符号时也不需要额外声明**，Windows下必须**显式的声明哪些符号需要导出**，且在引用其他共享库的符号时也要**显式声明需要导入的符号**。具体为：导出符号时使用`__declspec(dllexport)`声明，导入符号时使用`__declspec(dllimport)`声明，而且常见做法为使用宏定义

```C++
#ifdef WIN32
#define DllExport __declspec(dllexport)
#else
#define DllImport __declspec(dllimport)
#endif // !WIN32

class DllExport ExportClass : public XXX
{
  ....
};


// 同样使用的宏定义还有
#define WINAPI __stdcall // __stdcall是windows 下多数编程语言所采用的标准调用规范
// 而MSCV编译C语言时默认使用__cdecl调用规范
```

而且Windows下使用动态链接，除了DLL文件外，还需要.lib文件（导入库）以静态链接方式链接，因为.lib文件中包含了对象文件链接对应dll文件所需的导入符号，即dll的导出符号



#### 第十章 内存

栈的初始化是在入口函数执行之前就完成，因为入口函数中需要通过栈来传递命令参数、环境变量等；

而堆的初始化是在入口函数中完成的；

##### 内存分布

Linux下的**物理内存**分布（虚拟内存分布上是每个进程享有着所有的物理内存，但其实只有实际映射的那几块物理内存）：

从高到低的分别为内核区，

栈区（栈从高位到低位，栈顶在低位），

动态库映射区，

堆区（堆从低位到高位，堆顶在高位），

可执行文件映射区（可读可写区域，只读区域），

最后为保留区。

保留区是一系列受到保护而不允许访问内存区域总称，如NULL就是0x 0，不允许访问。

具体如下图所示：

![内存分布](..\图片\程序员的自我修养-images\内存分布.jpg)

所谓的**段错误Segment fault**（Segment就是从可执行文件装载角度看的段）

即为指针指向一个不允许读或写的内存区域，且指针试图解引用此地址空间！

##### 栈

>  请铭记，**系统执行一段程序是通过各个部件协作完成，而不是某一个部件直接完成，如调用函数中，代码段存放在对应的内存区域中，而函数内部的局部变量才存放在栈上**，后续还会看到涉及堆上空间的。
>
>  如通过**汇编的call指令，可以完成将函数返回地址（用于函数执行完毕后跳转到下一条语句）入栈和跳转到函数体中执行这两步**，这两步就涉及栈和代码段，如果函数中涉及全局变量，那么还会涉及数据段。

###### 栈上空间分布

| 栈空间分布（自上而下分别为栈底 --> 栈顶）        |
| ------------------------------ |
| 参数                             |
| 返回地址（此步骤和跳转到函数中执行，一般由call指令完成） |
| 旧的ebp                          |
| 保存的寄存器                         |
| 保存的局部变量                        |

![栈上空间分布](..\图片\程序员的自我修养-images\栈上空间分布.jpg)

32位Linux中，使用esp寄存器保存栈顶地址，而ebp寄存器则用来和eps一起标定一个函数的活动记录，即从ebp到esp的范围内属于当前的函数调用；当函数调用发生时，在参数入栈和call指令完成后，栈上还会将当前的ebp寄存器值入栈保存，作为旧的ebp，这样当函数调用完毕后，ebp再重新赋以此旧值，esp后退，那么就可以再次标定调用函数外部的函数，而新的ebp将被赋值为和esp相同。紧接着栈中将会把一些需要保存的现场寄存器值入栈，同时将局部变量入栈（esp会在入栈之前就向低位移动，以开辟栈空间），而且在寄存器入栈后，可能还会将一些调试信息也入栈。

```C++
int main()
{
  f();// 调用f函数时，旧的ebp将保存，新的ebp = esp，并伴随着新的入栈（esp向低位移动）
  // 两者标定f函数的活动范围
  // 而f执行结束后，
  return 0;
}
```

###### 无返回值的函数

###### 有返回值的函数

如果返回值为4字节内，那么将由eax寄存器保存；如果返回值在8字节以内，将由eax和edx联合返回，其中eax保存低4字节，ebx保存高的1~4字节。

如果返回值超出8字节（32位系统），会给函数传入一个隐式的参数，此参数是一块临时区域的地址，而此临时区域位于栈上开辟的空余空间，返回值时会根据此隐式参数所提供的临时空间地址，利用此临时内存空间来存放结果，然后将此值拷贝给调用方。（相当于多拷贝了一次：构造出对象后，先拷贝构造到临时内存，然后赋值给调用方），当然**编译器一般会做优化，将拷贝构造+赋值合并为赋值**，即直接把对象构造到临时内存，然后赋值，省去了中间的拷贝构造。

因为存在多次拷贝，所以返回一个自定义对象时需谨慎，可能会带来性能下降。

> ret汇编指令代表**从栈中取得返回地址，并跳转到该位置**（即函数返回并到此函数的下一句），而返回值是多少和此指令无关，一般在ret指令之前，返回值已经存入了eax寄存器或者已经拷贝到临时内存区域了。不要想当然的觉得return xx；那么ret指令就会附带返回值。

###### 函数调用规范

在函数调用中，涉及参数入栈，而参数有多个时怎么入栈呢？函数调用结束后，栈空间由谁负责清理（出栈）呢？调用方？还是被调用方自己？函数的名称修饰规则时怎样呢？

这些规定的不同代表着不同的调用规范，常见的调用规范有：

| 调用规范     | 出栈方        | 参数传递                                     | 名字修饰                                     |
| -------- | ---------- | ---------------------------------------- | ---------------------------------------- |
| cdecl    | 函数调用方      | 从右到左顺序入栈                                 | 下划线+函数名                                  |
| stdcall  | 被调用方（函数本身） | 从右到左顺序入栈                                 | 下划线+函数名+@+参数的字节数；如int func(int a, double b)修饰为_func@12 |
| fastcall | 被调用方（函数本身） | 头两个DWORD（4字节）类型或者占更少字节的参数被放入寄存器，其他剩下的参数按照从右到左的顺序入栈 | @+函数名+@+参数的字节数                           |
| pascal   | 被调用方（函数本身） | 从左到右顺序入栈                                 | 较复杂                                      |

其中`cdecl`是C++的默认调用规范，`stdcall`是Windows API的默认调用规范；C++还有自己的特殊调用规范`thiscall`，专用于类成员函数的调用，gcc中`thiscall`和`cdecl`基本一样，只不过this被作为函数的第一个参数。

##### 堆

**光有栈对于面向对象程序来说远远不够用，因为栈上数据在函数退出时会被释放，所以无法将数据传递到函数外部，而全局变量没办法做到动态产生，只能在编译时定义，所以堆的出现是一种必然；**栈就是一块大的内存区域，在程序主动放弃之前这块内存区域将会一直保持有效，而且栈上资源是跨线程共享的，可以用于线程间通信。

由于操作系统本身就可以管理内存资源，如果将进程的内存管理交由操作系统内核去完成，程序通过系统调用就可以完成内存申请、释放等，但是系统调用涉及到状态转换，本身性能开销较大，如果有频繁的系统调用，那么整个程序的效率将会极为低下；所以，**堆内存管理的思路即为：运行库通过系统调用向内核申请一块较大的内存空间，然后再向进程分配空闲的内存区域，如果已申请的内存空间耗尽，则运行库再去申请新的内存区域**，所以运行库需要能够向内核申请内存空间，并具有堆内存分配算法。

首先看各类系统的运行库是如何向操作系统内核申请内存空间，基本是将系统调用封装为对外的api。

###### Linux进程堆管理

系统调用：`mmap()`和`brk()`

```C++
void *mmap(
   void *start, // 申请空间的起始位，起始位传入0，则系统会自动挑选合适的起始位置
   size_t length, // 申请的空间长度 
   int prot, // 申请空间的权限 读写执行
   int flags, // 申请空间的类型 映射文件/匿名
   int fd, // 映射文件的套接字描述符
   off_t offset); // 映射文件的文件偏移
```

其中`mmap()`是向操作系统申请一段虚拟地址空间，这块虚拟地址空间可以映射文件（即文件的内存映射，大文件直接映射到内存，当作内存使用），如果**此空间没有用于映射文件，又称此空间为匿名空间（Anonymous），匿名空间可以作为堆空间**。不过，**mmap申请的内存空间要求起始位置和空间长度均为系统页大小的整数倍（因为内存映射是虚拟内存到物理内存的映射，按照页为单位，详见CSAPP 第9章 虚拟内存）**

所以运行库Glibc对外提供的申请内存API`malloc()`处理逻辑为：当用户申请小于128KB时，就从现有的堆空间中，根据堆分配算法分配空间并返回，如果超出128KB的请求时，使用`mmap()`函数为它分配一块匿名空间，然后在此匿名空间中为用户分配内存。

```C++
int brk(void* end_data_segment)
```

`brk()`函数作用为设置数据段的结束地址，从本章最初的那张图可以知道，数据段+BSS段（此处统称数据段）就在堆的下方（低位），紧挨着数据段的结束位置，如果设置数据段的结束地址在更低位，那就等于扩大堆空间，如果设置数据段的结束位置向高位移动，那就等于缩小堆空间。



###### Windows进程堆管理

Windows下提供的系统调用为`VirtualAlloc()`，和`mmap()`极为类似。	



> 个人理解：Windows下的栈和堆都很细碎，不像Linux划分了两个大的区域用于栈和堆，但是理论上来讲，进程是最小的资源分配单位，每个进程都有属于自己的堆，而每个线程都有属于自己的栈，其应该也是细碎的。从而涉及到不同角度的问题：从进程自己的虚拟内存空间来看，其堆和栈就类似于Linux，连续，但是从物理内存空间上看，即使是Linux下，堆和栈区也会被分割的极为细碎，属于不同的进程或内部线程，只不过和虚拟内存空间之间有着良好的映射关系。
>
> 故从虚拟内存空间来看，分配的空间必然是连续的；而从物理内存空间看，分配的空间极有可能是离散的，一块连续的虚拟内存空间可能是由若干块不连续的物理内存空间“拼凑”而成。

###### 内存分配算法

首先分配算法的功能为分配已有的空闲堆内存，并回收之前分配的**对应大小**的堆内存。

* 空闲链表


把堆中各个空闲的块按照链表的方式连接起来，当用户请求一块空间时，可以遍历整个列表，直到找到合适大小的块并且将它拆分；当用户释放空间时将它合并到空闲链表中。

首先需要一个数据结构来登记堆空间里所有的空闲空间，这样才能知道程序请求空间的时候该分配给它哪一块内存。在堆的每个空闲空间的开头或结尾处有一个头header，头结构中记录有上一个prev和下一个next空闲块的地址，即形成一个双向链表 

> 实现时应该是结构体中每个pre、next存放上一个、下一个内存空间的地址即可，不过存不存放自己当前开头或结尾地址？

缺点：没有分配的大小信息，当一块内存区域在释放时，无法单纯的通过此结构知晓需要释放多大的内存空间；所以一般在分配k字节内存时，实际分配k+4字节，多余4字节保存分配的内存大小。



![空闲链表分配](..\图片\程序员的自我修养-images\空闲链表分配.jpg)

分配后

![   空闲链表分配_2](..\图片\程序员的自我修养-images\空闲链表分配_2.jpg)



* 位图


针对空闲链表的缺陷，可以使用位图（Bitmap），其核心思想是将堆内存分为若干个等大小的块（block），申请内存时总是分配整数个块，而为了能够了解此次分配的大小，将分配的块的第一块称为已分配区域的头（Head），其余的块为已分配区域的主体（Body），从而将堆内存分为头、主体、空闲三种状态。

优点：整个堆的空闲信息存储在一个数组内，因此访问该数组时cache容易命中。

为了避免用户越界读写破坏数据，我们只须简单地备份一下位图即可。而且即使部分数据被破坏，也不会导致整个堆无法工作。

缺点：和分页管理一样，存在着内部碎片；如果为了减少内部碎片，而使得每个块很小，那么位图将会很大，可能失去了cache命中率高的优势，而且也会浪费一定的空间。基于此问题，可以使用**多级的位图**。（就像多级页表。。。）

> 实现应该是在堆中先维护一块管理区域，保存着这些连续块的分配信息；具体为：2位表示一块，然后用int存储即可。
>
> 11表示头Head，10表示主体Body，00表示空闲Free
>
> 以前OS中的位图一般讲解是1位表示一个块

![位图分配](..\图片\程序员的自我修养-images\位图分配.jpg)



* 对象池


其实对象池不能算作分配算法，它主要针对程序中所分配的内存大小均为固定大小或者说只有几种类型大小（应用中较常见）。

对象池的思路很简单，如果每一次分配的空间大小都一样，那么就可以按照这个每次请求分配的大小作为一个单位，把整个堆空间划分为大量的小块，每次请求的时候只需要找到一个小块就可以了。

具体的实现中还是会用到空闲链表、位图或者两者同时使用。



实际上很多现实应用中，堆的分配算法往往是采取多种算法复合而成的。

比如对于glibc来说，它对于小于64字节的空间申请是采用类似于对象池的方法；而对于大于512字节的空间申请采用的是最佳适配算法；对于大于64字节而小于512字节的，它会根据情况采取上述方法中的最佳折中策略；对于大于128KB的申请，它会使用mmap机制直接向操作系统申请空间。

##### 遇到的问题

1、P299页的小实验中，对foo函数定义时采用了`cdecl`调用规范，而调用方申明时采用了`fastcall`调用规范，按照书中所言应该因为规范问题（两种方式的函数修饰不同）导致链接失败，即调用方未找到对应的符号；但是我在windows端实验时发现编译链接一切正常，运行结果也正确；故在linux端再次实验，发现和windows端相同；打开对应的目标文件，发现两个文件中的符号名也是一致的。

于是怀疑为32位系统和64位系统差异，或者说64位系统下两种调用规范至少在函数修饰方面没有差异！于是linux中使用`gcc -m32 -o test a.c b.c`编译链接，出现报错`fatal error: bits/libc-header-start.h`，查询后发现为系统中缺少交叉编译的gcc库，于是`apt-get install gcc-multilib`后再次构建，发现同样没有产生链接错误，但是运行结果出错，参数匹配是错误的！！

**结论：**那么至少说明在64位系统中编译32位输出文件时，cdecl和fastcall的函数修饰相同，但是两者的参数入栈顺序仍然不同；而在64位系统中使用64位输出文件时，两种调用规范完全无差异！



#### 第十一章 运行库

运行库（Runtime Library）是个很大的概念，负责程序的初始化、结束以及过程中调用的标准函数、IO、堆实现等，而且从某种程度上运行库是C语言程序和不同操作系统内核之间的抽象层，在底层实现上运行库会调用各自平台的系统调用，即实现不同，而对使用者而言，其采用同一套统一的接口；C语言的运行库即称为CRT。

C语言运行库包含如下功能：

1）启动与退出：入口函数（`_start()`）以及入口函数所依赖的函数（入口函数中才会真正的调用`main()`）

后续为了支持`.init` `.finit`的启动代码，在启动和退出时针对`.init` `.finit`段（会在`main()`之前/之后运行）做了支持。

不过C++的全局构造和析构（也在`main()`之前/之后运行），但却不是直接放在`.init`和`.finit`段中，只是在这两个段中提供了全局构造和析构的调用机制，它的实现是由GCC完成的，GCC会提供两个目标文件`crtbeginT.o`和`crtend.o`来配合glibc实现C++的全局构造和析构。

> 毕竟全局构造和析构是C++特性，而glibc只是C语言运行库，C++特性还需要GCC完成！

2）标准库

3）I/O：I/O功能的封装与实现

4）堆：堆的封装与实现，如堆的初始化

5）语言实现：语言中的特殊功能实现

而常说的Glibc和MSVC CRT是**C语言运行库**（不是C++）的超集，对C语言标准库做了扩展，如操作线程。





**函数变长参数**的实现，本质上借助了参数会保存在栈中，只要知晓参数的数量，以及对应的调用规范，就可以根据指针找到具体参数。



##### Glibc

##### MSVC CRT

MSVC CRT（Microsoft Visual C++ C Runtime）伴随着Visual C++发布，同一个版本的MSVC CRT根据不同属性提供多种子版本，按照静态/动态链接，可以分为静态版和动态版；按照单线程/多线程，可以分为单线程版和多线程版；按照调试/发布，可分为调试版和发布版；按照是否支持C++分为纯C运行库版和支持C++版；按照是否支持托管代码分为支持本地代码/托管代码和纯托管代码版。这些属性很多时候是相互正交的，也就是说它们之间可以相互组合。比如可以有静态单线程纯C纯本地代码调试版；也可以有动态的多线程纯C纯本地代码发布版等。但有些组合是没有的，比如动态链接版本的CRT是没有单线程的，所有的动态链接CRT都是多线程安全的。

基于此，微软给静态库和动态库提供了两种不同的库命名方法，静态版的CRT位于MSVC安装目录下的lib/，比如Visual C++ 2008的静态库路径为“Program Files\Microsoft Visual Studio 9.0\VC\lib”，它们的命名规则为：

```c++
libc [p] [mt] [d] .lib

// p 表示 C Plusplus，即C++标准库。

// mt表示 Multi-Thread，即表示支持多线程。

// d 表示 Debug，即表示调试版本。

```

动态版的CRT的每个版本一般有两个相对应的文件，一个用于链接的.lib文件，一个用于运行时用的.dll动态链接库。它们的命名方式与静态版的CRT非常类似，稍微有所不同的是，CRT的动态链接库DLL文件名中会包含版本号。比如Visual C++ 2005的多线程、动态链接版的DLL文件名为msvcr90.dll（Visual C++ 2005的内部版本号为8.0）；自从Visual C++ 2005（MSVC 8.0）以后，MSVC不再提供静态链接单线程版的运行库（LIBC.lib、LIBCD.lib）。

![MSVC运行库命名](..\图片\程序员的自我修养-images\MSVC运行库命名.jpg)

![MSVC运行库命名-C++](F:\Markdown\研一上\图片\程序员的自我修养-images\MSVC运行库命名-C++.jpg)

可以看出此命名和Visual Studio中编译器中的配置选项也有着对应关系，编译器默认选择`libcmt.lib`



##### 问题 1

**Q：如果一个程序里面的不同obj文件或DLL文件使用了不同的CRT，会不会有问题？**

1、如果程序没有用到DLL，完全静态链接，不同的obj在编译时用到了不同版本的静态CRT。

由于目前静态链接CRT只有多线程版，并且如果所有的目标文件都统一使用调试版或发布版，那么这种情况下一般是不会有问题的。

如果使用的调试和发布版本也不一样，可能是有问题的。

2、如果程序的不同目标文件依赖于不同的动态运行库，甚至有些目标文件依赖于静态运行库，有些依赖于动态运行库，那么很有可能出现的问题就是无法通过链接。

链接器对这种情况的具体反应依赖于输入目标文件的顺序，有些情况下它会报符号重复定义错误：

MSVCRTD.lib(MSVCR80D.dll) : error LNK2005: _printf already defined in LIBCMTD.lib (printf.obj)

但是有些情况下，它会使链接顺利通过，只是给出一个警告：

LINK : warning LNK4098: defaultlib 'LIBCMTD' conflicts with use of other libs; use /NODEFAULTLIB:library

如果碰到上面这种静态/动态CRT混合的情况，我们可以使用链接器的/NODEFAULTLIB来禁止某个或某些版本的CRT，这样一般就能使链接顺利进行。

3、如果程序依赖的dll文件分别使用了不同的CRT

在一般情况下，这个程序应该能正常运行，但是值得注意的是，你不能够在这些DLL之间相互传递使用一些资源。

比如两个DLL A和B分别使用不同的CRT，那么应该注意以下问题：

a）不能在A中申请内存然后在B中释放，因为**它们分属于不同的CRT，即拥有不同的堆！！**，这包括C++里面所有对象的申请和释放；

b）在A中打开的文件不能在B中使用，比如FILE*之类的，因为它们依赖于CRT的文件操作部分。

还有类似的问题，比如不能相互共享locale等。如果不违反上述规则，可能会使程序发生莫名其妙的错误并且很难发现。

防止出现上述问题的最好方法就是保证一个工程里面所有的目标文件和DLL都使用同一个版本的CRT。



> 之前雷达数据转发项目中遇到的netifi动态库和rabbitmq动态库问题，一个使用了debug版本，另一个使用了release版本的运行库，导致程序链接出错，最后通过重新编译netifi动态库为release版本解决问题。



##### 运行库与多线程

由于多线程在现代的程序设计中占据非常重要的地位，主流的C运行库在设计时都会考虑到多线程相关的内容。一般分为两个方面：1）运行库能否提供多线程操作的接口，如创建线程、退出线程、设置线程优先级；2）运行库本身能不能在多线程环境下运行。

###### 早期运行库

针对第一方面，运行库均会提供相应的接口，如MSVC下的`_beginthread(),_endthread()`，Glibc下的`pthread`库，而这些接口毫无疑问都是平台相关的。

针对第二方面，最早的运行库是线程不安全的，如

a）`errno`

这个变量最初被设计为全局变量，在多线程环境下，上一个线程产生的错误码就有可能在读取出来之前被另一个线程覆盖，从而导致获得错误的出错信息；

b）`strtok()等`

此类函数都会**使用函数内部的局部静态变量来存储字符串的位置**，不同的线程调用这个函数将会把它内部的局部静态变量弄混乱 PS：网络编程的底层api很多都使用了函数内部局部静态变量，所以也不是线程安全

c）`malloc()、delete()`

最初的堆分配/释放函数或关键字在不加锁的情况下是线程不安全的。由于这些函数或关键字的调用十分频繁，因此在保证线程安全的时候显得十分繁琐；

d）异常处理

在早期的C++运行库里，不同的线程抛出的异常会彼此冲突，从而造成信息丢失的情况。

e）`printf()、fprintf()`及其他IO函数

流输出函数同样是线程不安全的，因为它们**共享了同一个控制台或文件输出。不同的输出并发时，信息会混杂在一起**。

f）包含信号处理在内的其他线程不安全函数



###### CRT的改进

所以运行库在后期的改造中增加了对应的多线程能力，如提供新的多线程下api或者修改对应实现，如`strtok_s()`和Glibc的`strtok_r()`（改进的api，要求传入一个用于结果存放的字符串指针），使其线程安全；不过目前的运行库基本都有着对应的多线程版本，甚至MSVC已经废弃了单线程的静态运行库，仅有多线程静态运行库，而动态运行库仍然存在单线程和多线程两个版本。

具体措施有：

a）使用TLS



b）加锁

c）改进函数调用方式

如`strtok_r()`



###### TLS的实现

为了线程安全，线程需要使用独有内存区域来保存一些只属于本线程的数据，如`errno`；但线程的独有内存区域仅为栈和寄存器，其中栈存在随着函数的结束而出栈的问题，无法一直保存数据，而寄存器则数量和大小有限，所以新增了一个TLS（Thread Local Storage）区域用于线程专用。

TLS是在堆内存上分配一块内存区域，然后交由线程独有；具体做法来讲，以MSVC为例，当定义一个全局变量为线程私有变量（`__declspec(thread)` / `__thread`），此变量会存入`.tls`段而非`.data/.bss`，当启动一个新的线程时，会从进程堆空间中分配一块足够大小的空间，将.tls的内容复制进去，于是每个线程都有了一个独有的.tls副本。

```c++
__thread int number；

__declspecc(thread) int number;
```

而访问此空间地址的机制为：Windows系统中针对每个线程有一个信息结构体，叫做线程环境块（TEB，Thread Environment Block），此结构中保存有线程的栈地址，线程ID等信息，其中就包含一个TLS数组，该数组首元素即为指向该线程的`.tls`副本的地址，而对于每个线程来说，x86的FS段寄存器所指的段就是该线程的TEB，TLS数组在TEB的偏移量为0x2C；所以当需要访问一个线程的TLS变量时，首先通过寄存器+偏移量找到TEB中的TLS数组，然后由数组首元素访问`.tls`段，段中加上变量偏移量即可访问该变量。

> TLS数组：首元素为线程tls副本的地址，其他元素为显式申请的TLS变量，数组长度为64，但是可以做二级数组扩展显式TLS变量数量

如果该TLS变量是全局对象，即需要初始化 -- 调用其构造函数，并且在线程退出时调用析构函数，释放该对象，那么就不能简单的当作变量对待，还需要保存好对应的构造函数和析构函数的地址。其具体实现为：Windows PE文件中有个叫数据目录的结构，其中有个元素是TLS表的地址和长度，而TLS表中保存有所有TLS变量的构造和析构函数的地址，从而保证了线程启动和退出时TLS变量的正确初始化和释放。

Q：TLS表本身存放在哪？还有前面所说的TEB存放在哪？

**A：TLS表本身存放在`.rdata`段**

**x86的FS段寄存器所指的段就是该线程的TEB**



##### 问题 2

Windows下 Windows API的`CreateThread()`和MSVC CRT的`_beginthread()、_beginthreadx()`均可以创建线程，有什么区别？

CRT创建线程时本质上还是会调用Windows API，但是它在调用`CreateThread()`之前会先处置好**诸如线程ID、线程句柄、erron、strtok()的前一次调用位置、rand()函数的种子、异常处理等与CRT有关的而且是线程私有的信息**，这些信息会被放入一个`_tiddata`的结构体中，此结构体的指针最终会存入之前所说的TLS数组；可见`_beginthread()`的实现并没有采用`__declspecc(thread)`的方式，而是直接在堆内存中申请`_tiddata`结构，把线程私有变量存放在结构中，然后将结构的指针存入到TLS数组。都借助了堆内存，只不过一个是`.tls`段，一个直接开辟内存存放数据结构。

那么理论上来讲，如果使用`CreateThread()`创建线程，而又在此新建的线程中调用CRT的`strtok()`，线程安全的此函数需要使用线程私有变量，如果使用Windows API而导致没有`_tiddata`结构，理应报错，但实际上并没有报错，因为`strtok()`的实现中会去获取`_tiddata`结构，如果发现线程没有申请此结构，则会主动申请并初始化该结构，所以不会报错。

但是此结构的释放，也随之需要由CRT来释放（**谁申请谁释放**，而且Win API根本不知道`_tiddata`这样一个结构的存在），如果在线程释放时调用了Window API`ExitThread()`，而非CRT的`_endthread()`，那么线程释放时，堆上的`_tiddata`结构就无法获得释放，**内存泄漏**随着发生。

所以，当使用CRT时（基本上所有的程序都使用CRT），请尽量使用`_beginthread()/_beginthreadex()/_endthread()/_endthreadex()`这组函数来创建线程



##### C++全局构造和析构

![入口函数中构造的调用顺序](..\图片\程序员的自我修养-images\入口函数中构造的调用顺序.jpg)

入口函数需要负责全局对象的构造和析构，所以Glibc的入口函数`_start`中的调用顺序是：`_start` -> `__libc_start_main` ->`__cxa_atexit(rtld_fini, NULL, NULL);// 动态加载有关的收尾工作` -> `__libc_init_first` -> `__cxa_atexit(fini, NULL, NULL);` -> `(*init)(argc, argv, __environ) // 实际就是__libc_csu_init` -> `main` -> `exit` -> `_exit`

main函数的返回值将会作为exit的参数，所以exit是必然会被调用的，exit中又会将atexit函数中注册的函数调用。

> atexit的作用是将注册的函数在main函数执行后运行
>
> atexit接受一个函数指针作为参数，并保证在程序正常退出（指从main里返回或调用exit函数）时，这个函数指针指向的函数会被调用



对于每个编译单元(.cpp)，GCC编译器会遍历其中所有的全局对象，然后为此单元中全局对象生成一个叫做`GLOBAL__I_Hw`的函数，**此函数负责此编译单元所有的全局\静态对象的构造和析构**

```c++
static void GLOBAL__I_Hw(void)
{
    Hw::Hw(); // 构造对象
    atexit(__tcf_1); // 一个神秘的函数叫做__tcf_1被注册到了exit
}
```

一旦一个目标文件里有这样的函数，编译器会在这个编译单元产生的目标文件(.o)的`.ctors`段里放置一个指针，这个指针指向的便是`GLOBAL__I_Hw`。换言之`.ctors`段中仅仅存放一个指针。

所以编译器会为每个编译单元(`.cpp`)的全局/静态对象生成此函数和`.ctors`，当链接器将所有的`.ctors`合并到一起时，就类似与一个函数指针数组，而GCC的`crtbegin.o`本身也包含一个`.ctors`，会被放在所有`.ctors`的最前面，其中存储着4个字节的1，此时链接器会将这4个字节改为全局构造函数的数量，然后将此段的起始地址定义为符号`__CTOR_LIST__`；而GCC的`crtend.o`就是一个0，然后定义了一个符号`__CTOR_END__`，指向段末尾。

而我们知道，全局对象的构造和析构是发生在main函数之前/之后的，对应于`.init`和`.finit`段，可执行文件中的这两个段实际是由所有目标文件的`.init`和`.finit`段合并而成（C++对象实际还需要GCC提供的`crtbegin.o`和`crtend.o`），最终形成的代码即为`_init()`和`_finit()`函数，并且会在入口函数中被调用。而查看`_init`函数的反汇编会发现其中又会调用一个叫做`__do_global_ctors_aux`的函数，此函数来自于`crtbegin.o`，查看函数实现：
```c++
void __do_global_ctors_aux(void)
{
    /* Call constructor functions.  */
    unsigned long nptrs = (unsigned long) __CTOR_LIST__[0]; //__CTOR_LIST__ 的首元素为构造函数的数量 
    unsigned i;

  	// 遍历__CTOR_LIST__的剩余元素，显然其他元素均为函数指针，相当于调用函数
  	// __CTOR_LIST__存放的是所有全局对象的构造函数的指针
  	// 当i == 0时就代表__CTOR_END__
    for (i = nptrs; i >= 1; i--)
         __CTOR_LIST__[i] ();
}
```

发现此函数实际就是将.ctors段中的所有全局/静态对象构造函数调用一次，从而实现了在main之前调用；当main函数执行完成，在`GLOBAL__I_Hw`中注册的`atexit`实际是析构函数，此时就会被调用，而且此时的析构调用顺序（即`atexit`中的注册反序（出栈））刚好和构造顺序严格反序！！

```
// 可以看出__tcf_1实际就是析构
static void __tcf_1(void) //这个名字由编译器生成
{
    Hw.~HelloWorld();
}
```

如果不采用`atexit`的方式执行析构，那么就需要和构造函数的实现一样，产生一个.dtors段，每个目标文件中的此段均指向生成的析构函数地址，然后合并成`__DTOR_LIST__`，最终在main执行完成后调用，但这就要求dtors段的合并顺序必须是ctors段合并顺序的反序，会增加链接器工作量，改为采用`atexit`

> `.init`段和`.ctors`段不可混为一谈，ctors是纯C++的对象构造析构，只不过在合成之后由init段中的代码负责调用罢了，而init段负责所有main函数之前的操作，ctors只是其中一部分，也只是init段中__do_global_ctors_aux函数！



MSVC中也采用类似的方式，构造函数的指针放在`.CRT$XCA 到.CRT$XCZ`段（类似ctors）中并最终合并成一个段放在`.rdata`中，其中`.CRT$XCA`和`.CRT$XCZ`类似于`__CTOR_LIST__` 和 `__CTOR_END__`，而析构函数也是通过atexit的方式注册，以便在main之后调用。





##### 遇到的问题

在Ubuntu 20版本系统中测试了全局对象的构造与析构，但是奇怪的是最终可执行文件中并没有产生ctors段，而是有`.init_array`和`.fini_array`；

符号表中有编译器生成的`_GLOBAL__sub_I_hw`，反汇编后可以看到其中调用了`_Z41__static_initialization_and_destruction_0ii`负责构造函数和atexit 析构函数，但是没有`__do_global_ctors_aux`，而是存在一个`__do_global_dtors_aux`

那么是不是说现在的全局对象构造和析构方式有所更改？





#### 第十二章 系统调用

由于操作系统负责和硬件的交互，而应用程序不能直接去修改硬件的内容，所以操作系统提供了一组接口，用于实现应用系统与硬件之间的交互（如文件读写，网络，IO等），这组接口即为系统调用；

在现代操作系统中，通常也据此有两种特权级别，分别为用户模式（User Mode）和内核模式（Kernel Mode），也被称为**用户态**和**内核态**。由于有多种特权模式的存在，操作系统就可以让不同的代码运行在不同的模式上，以限制它们的权力，提高稳定性和安全性。普通应用程序运行在用户态的模式下，诸多操作将受到限制，这些操作包括访问硬件设备、开关中断、改变特权模式等。而系统调用即运行在内核态上。

系统调用是运行在内核态的，而应用程序基本都是运行在用户态的。用户态的程序如何运行内核态的代码呢？操作系统一般是通过中断（Interrupt）来从用户态切换到内核态。类似的实现还有轮询（Poll），即CPU不断的询问应用程序是否需要访问内核态，显然这会造成极大的CPU算力浪费；而中断的机制为CPU仍照常运行，而应用程序在需要访问内核态时主动联络CPU，CPU停下当前正在运行的程序，转而运行主动触发CPU的程序。

中断一般具有两个属性，一个称为**中断号**（从0开始），一个称为**中断处理程序（Interrupt Service Routine, ISR）**。不同的中断具有不同的中断号，而同时一个中断处理程序一一对应一个中断号。在内核中，有一个数组称为**中断向量表（Interrupt Vector Table）**，这个数组的第n项包含了指向第n号中断的中断处理程序的指针。当中断到来时，CPU会暂停当前执行的代码，根据中断的中断号，在中断向量表中找到对应的中断处理程序，并调用它。中断处理程序执行完成之后，CPU会继续执行之前的代码。

![中断过程](..\图片\程序员的自我修养-images\中断过程.png)

对于同一个中断号，操作系统如何知道是哪一个系统调用要被调用呢？和中断一样，系统调用都有一个系统调用号，就像身份标识一样来表明是哪一个系统调用，这个系统调用号通常就是系统调用在系统调用表中的位置，例如Linux里fork的系统调用号是2。这个系统调用号在执行int指令前会被放置在某个固定的寄存器里，对应的中断代码会取得这个系统调用号，并且调用正确的函数。**以Linux的int 0x80为例，系统调用号是由eax来传入的。用户将系统调用号放入eax，然后使用int 0x80调用中断，中断服务程序就可以从eax里取得系统调用号，进而调用对应的函数。同时eax还会用于保存函数的返回值。**

##### Linux的经典系统调用实现（早期）

首先申明，以下只是Linux的系统调用，Glibc采用了本质相同，但是过程不同的系统调用实现。

![Linux中断流程](..\图片\程序员的自我修养-images\Linux中断流程.png)

Linux经典系统调用使用汇编`int + 0x80`中断来实现，0x80即为其中断号，而由于中断号很有限，所以并不会用来对应具体的系统调用，系统调用有其自己的系统调用号，对应于系统调用表的下标；0x80号中断对应着一系列的系统调用，其中断处理程序名为`system call`，`system call`中再根据寄存器eax传入的系统调用号，调用具体的系统调用函数，如`fork`对应的系统调用号为2，会最终调用函数`sys_fork`。

由于0x80中断发生时，执行场所已经转换到核心态，所以还需要完成**栈的切换**，从用户态栈转换到核心态栈，因为用户态和内核态使用的是不同的栈，两者各自负责各自的函数调用，互不干扰。

```C++
define SYSCALL_VECTOR 0x80 // Linux/include/asm-i386/mach-default/irq_vectors.h

set_system_gate(SYSCALL_VECTOR,&system_call); // Linux/arch/i386/kernel/traps.c 中断向量表部分定义


// 系统调用表 Linux/arch/i386/kernel/syscall_table.S
.data
ENTRY(sys_call_table)
    .long sys_restart_syscall    
    .long sys_exit
    .long sys_fork
    .long sys_read
    .long sys_write
    ......
```



###### 以fork为例

```
int main()
{
    fork();
}
```

当程序中调用fork时，fork函数是一个对系统调用fork的封装，可以用下列宏来定义它：

```
_syscall0(pid_t, fork); // 适用于无参数的系统调用封装的宏函数
```

它的第一个参数为这个系统调用的返回值类型，这里为`pid_t`，是一个Linux自定义类型，代表进程的id。`_syscall0`的第二个参数是系统调用的名称`，_syscall0`展开之后会形成一个与系统调用名称同名的函数。

此宏定义展开后是AT&T格式的**汇编**，**内容为首先禁用编译器优化，其次使用eax保存系统调用号`__NR_fork`，之后产生中断`int 0x80`，最后eax还会用于保存函数返回值，并且还会通过另一个宏将返回值转换为C语言风格**。

> Linux中系统调用使用返回值传递错误码，如果返回值为负数，那么表明调用失败，返回值的绝对值就是错误码。
>
> C语言中使用errno（多线程下保存在TLS）保存错误码，返回-1表示调用失败。

**PS：**以上的fork是无参数系统调用，x86下Linux支持的系统调用参数至多有6个，分别使用6个寄存器来传递，它们分别是EBX、ECX、EDX、ESI、EDI和EBP，所以其他有参系统调用的区别就在于宏展开的汇编中使用寄存器保存参数。

当中断`int 0x80`发生，在实际执行中断向量表中的第0x80号元素所对应的函数之前，CPU首先还要进行栈的切换。栈必须从用户栈切换到内核栈。从中断处理函数中返回时，程序的当前栈还要从内核栈切换回用户栈。切换时，**内核栈会保存用户栈中ESP、SS的值**（记住是内核栈保存），返回后再行恢复。

栈切换之后，转而执行其中断处理程序`system call`，其会首先保存所有寄存器（`SAVE_ALL`），将各种寄存器压入栈中，以免它们的值被后续执行的代码所覆盖，此时如果系统调用是有参的，而其参数“恰”保存在寄存器中，从而内核里的系统调用函数就可以正确地获取用户提供的参数了。

![系统调用时的堆栈分布](..\图片\程序员的自我修养-images\系统调用时的堆栈分布.png)



调用流程

`main -> fork  -> int 0x80 -> system call -> sys_fork`



##### Linux的新型系统调用机制

vdso 虚拟动态共享库（Virtual Dynamic Shared Library，VDSO），在之前讲动态库时提到过，当时说是用于访问内核态，其实就是用于系统调用。它会被装载到固定位置，里面使用了intel提供的用于系统调用的新指令：`sysenter`和`sysexit`；调用`sysenter`之后，系统会直接跳转到由某个寄存器指定的函数执行，并自动完成特权级转换、堆栈切换等功能。而参数传递方面，新型的系统调用和使用int的系统调用完全一样，仍然使用EBX、ECX、EDX、ESI、EDI和EBP这6个寄存器传递。在内核里也是通过`SAVE_ALL`将这些参数放置在栈上。



#### END

Windows系统调用暂时未看

运行库实现暂时未看

至此，本书完结，转到 csapp 深入理解计算机系统特定章节，相信和本书会有部分重叠知识点，也相信本书会给我真正理解C\C++带来巨大助力！