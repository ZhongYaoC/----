8zab fast election

此选举算法，不同于raft中的一节点一票，fast election一节点可以投出多张选票，根据对比收到的来自其他节点的选票，不断的更新自身的选票信息，以选出最佳的leader节点





注意点：

LOOKING状态才会投选票！

节点通过对比收到的选票，在需要更新自身选票时才会重新广播新的选票，否则不会有回复信息；广播的数据包含（electionEpoch、voteforid、voteforzxid）选举任期号、投给哪台服务器、被投的那台服务器的last zxid



比较节点信息新旧时，采取zxid 和 server id协同比较，所以不可能得出某两个节点的数据同样的结论，也就避免了集群启动时，节点均投给自身，然后选举无法进行下去的可能。



节点状态的修改触发：每个节点检查自身票箱，如果某个节点已经获得大多数以上选票，并且等待一个较短时期（如RTT/2？）后未收到其他选票，即修改自身状态（等待一个时期，以避免非最优节点变成leader）

> 票箱用`map<server_id, voteforid>`实现，检索票箱中某个节点有无达到半数以上，用map或者hash table版map实现，`map<server_id, count>`，其server_id源自于票箱的voteforid，如每次票箱更新，此统计map同步更新

FOLLOWING节点如果收不到心跳包（超时处理），判定leader失效，此时修改状态为LOOKING，发起选举



非集群启动时：

1、某follower宕机重启

1）此follower宕机时，leader已经选出

follower重启后，发起选举，epoch+1，会使得其epoch与其他节点epoch不相等，说明此刻不需要选举，此选票会放入outofelection票箱，统计其中得到大多数同意的节点，告知其当前leader并修改状态为FOLLOWING

2）此follower宕机时，leader未选出

则此时follower重启后，本地epoch+1，会与选出leader后的epoch相等，~~所以follower的选票发出后，可能会继续参与选举；~~

选票接收方会检查票箱中是否已经有大多数同意的节点，是则告知此follower，并修改状态为FOLLOWING（也就是说其他未宕机节点已经不是LOOKING状态了）；

否，则正常继续选举



2、leader宕机重启

其他follower节点未收到心跳信息，修改状态为LOOKING，并发起新一轮选举，选出新的leader；旧leader在新leader选出后重启成功，则类似上述1的情况；旧leader在新leader选出前重启成功，则加入选举即可



节点重启后的默认状态应该是LOOKING状态。



目前疑问点：

选举的触发条件？ leader宕机多久后发起？

发起选举方是同时开始吗？

选举过程是交互式吗？或者说是问答式的吗？

如何区分是集群初始启动还是运行过程中有服务器重启重选举？或者说需要区分吗

epoch何时持久化，只有本次选举出leader后，epoch才会持久化，即自增的那个epoch未持久化，持久化的epoch是current epoch

outofelection票箱



如果由于网络等现实因素的存在，会出现非最优的节点被选为leader，而最优的节点可能才刚开始发出选票或者排到了选票接收队列的后方，还未被处理，这时其他节点的选举已经结束，导致最优节点被漏掉了（zab源码中通过超时来解决这个问题，即最后确定各节点状态前，等待一段时间，此时段内有新选票到来则推迟确定状态，否则直接确定状态，即尽可能等待所有节点的选票到达）

所以FastElection选出来的节点不一定是拥有最新数据的节点，但选出该节点不会违背zab的保证：只要被commit过的数据就不会被删除，哪怕只被一个节点所commit；上述情况中被删除的那部分数据还未被commit









ElectionTrigger:

在手动将leader宕机后，剩余节点发送广播，发现Handle Write进入失败，怀疑connection直接被关闭了





20220318调试笔记：

实验环境：三独立进程模拟三台服务器1、2、3，其中程序开始时手动设置服务器1为leader，2、3为follower；connection状况为：服务器1主动连接服务器2、3，服务器2主动连接3；

过程：模拟leader宕机，手动关闭服务器1进程，服务器1与2、3之间的连接被检测到中断，此时2、3之间连接应该仍然存在，从而在下一轮loop中2、3服务器发起prevote，然后选举；（现修改为两台服务器1、2，检查网络通信故障点）

问题：关闭服务器1后，2、3服务器的心跳检测超时运行正常，但是在Tcp->BrdMsg时，handle write未能进入，然后两进程直接被终止

思考：增加日志打印后发现，服务器1关闭后，发送FIN，所以接收的select读就绪，并返回值iRet为1，然后进入handle read，recv == 0（EOF） ，从而导致触发connection的错误处理，在消息队列中加入AddMsg，从而在本轮的loop中析构与服务器1的connection（ProcessMsg()），（疑问：错误处理中还会根据 ! isserver来判断是否由connector发起重连，三台服务器时，1、2服务器均为connector持有方，即使2、3间连接存在，也会尝试重连），在loop紧接着的poller->ProcRmEvent()中将此connection从fd Set中移除（？？此处有点疑问，poller是通过map< fd, EventHandler* >来移除的，那么此时Handler指针已经被析构？哪来的rmflag）

进入下一轮loop，select无就绪，超时返回值0，也就是进行正常的超时处理，执行心跳超时回调，累计触发到4心跳超时后（4轮loop的超时处理），在第五次触发时，调用NotifyLeaderDownToOther，试图发送prevote广播包（加入消息队列，待发），则在本轮的loop中触发消息队列处理（ProcessMsg()）：组包，发送给除本机外的所有服务器（包含已经关闭的服务器1，因为广播是通过从配置文件中读出的节点集合来发送的，而服务器1的connection在之前的错误处理中已经从connectionMap中删去，所以会触发doNewConnector，正常应该连接失败，return掉），加入发送队列，打开写集；

针对与服务器3的通信：下一轮loop中select 返回 >0，进入handle write，发送出去

针对与服务器1的通信：触发doNewConnector，会首先检查已有的connectorMap中有无此ipport，没有就新建connector，发起重连；由于之前是服务器1连接2，所有没有connector，所以新建





但是在进入消息队列处理后，进入doclntDealSndData执行时，进程直接结束！！

增加日志发现，之前的删除connection，find失败，也就是说connecion没被删掉；但是在之后广播时，find 这个connection是能找到的，严重怀疑，删除时和发送时的ipport不一样，导致错误，发送时合成的ipport肯定正确的，因为这是从配置文件中取出的；但是之前心跳是怎么发通的？？？心跳为省事用的也是TCP啊



bug1：connectionMap的key值是根据who am i来的，也就是配置文件中节点配置；但删除时（Connection::ErrProcInLoop）确实根据connection内的对端ip和port，这个值最初是根据accept解析直接获取的，但是发出端的端口是随机选择的，所以这个port和配置文件中的port完全不同；

bug fix1：在收到who am i后，根据who am i包内容修改connection的peeraddr和peerport；确保之后的删除正常



bug2：服务器1被关闭后，进入下一轮loop，发现select 返回-1，errno = 10038（使用了在一个非套接字上尝试了一个操作），析构connection成功，但是poller中的fd显然未被移除出去！导致原有connecction的fd在被重置为-1后再次被监听；（加断点检查，的确如此，poller的eventHandlerMap中还存有本该被删除的connection）





bug fix2：在delConn中，将poller中的rm flag修改为delete，从而将析构connection和从poller的map中删除connection推迟到poller中统一完成。最初版本的delConn中仅析构了connection



bug3：服务器1关闭后，服务器2、3交互选出新的leader服务器3，但是服务器3当选后，未发出新的leader心跳包，导致2、3服务器仍处于follower行为，再次触发选举超时，无限选主



bug fix3：修改了类结构，Trigger类作为总的启动类，FastElection类由Trigger类创建，且注册了选举类选出leader后的发送心跳包回调



bug4：服务器1关闭后，服务器2、3交互选出新的leader服务器3，服务器3正常发出心跳包，此时选择将服务器1重启，因代码中Trigger Init时会针对leader节点，主动发送心跳包，且代码中手动写死初始leader为服务器1，导致服务器1也发出心跳包，部分服务器出现leader错误



bug fix4（ ing）：目前想法是，服务器启动时不手动设置leader，而是采取leader = null，然后马上发起选举；此想法也符合正常集群冷启动的逻辑，但是这在某种程度上，要求服务器全部同时启动；

回到bug 4的场景，服务器1重启，leader == null，发出选举选票，其逻辑时钟小于服务器2、3（此处应该修改，逻辑时钟应该被持久化），按照原有代码逻辑，此类选票会被直接无视，应修改为告知其当前leader，加入集群；

另收到心跳包后，应该在应用层面判断收到的心跳包是否来自现有leader，否则心跳很容易被伪造！！即不论是谁发出的心跳包，都会重置本机当前的选举超时计时器





或者收到心跳后，判断心跳包的发出方，如果该发出方不等于当前本机的leader，发送回复报文，告知其当前新leader，然后“假”心跳发出方，修改自身当前leader和状态位（相当于把fast leader中收到逻辑时钟小于当前的那部分逻辑移到心跳这里）





最大的问题，现在所有的leader state flag都没有持久化，所以原有leader重启后，状态位等都不对，fast election中的发出方状态位FOLLOWING、LEADING等都没用到，本来收到此类状态发来的消息，应告知其现有leader等信息，可以避免一部分问题。但好像没法避免原leader重启后重新发出心跳包的情况，除非逻辑改为重启后直接发开始选举，但这样的话，要求所有服务器同时启动的问题又出现了

现有的解决方案就类似于：集群冷启动的时候，手动指定leader，之后leader宕机选出新的leader，如果这个leader重启或修复好后，原leader再发一次心跳，接收方会纠正其状态，从而接收新leader；纠正这个地方必须增加统计，达到半数以上才可以认定新leader，否则会误发纠错报文，即会出现纠错报文本身就是错的（纠错即争夺谁才是真的leader）

增加上述机制后，如果follower宕机后重启，收到新leader发来的广播，会与自身认知的leader = 1冲突，反而发出纠错报文

纠错机制，越来越像是只进行一轮次的Fast Election了。。



bug 5：三台启动，服务器1作为leader，宕机，3当选新leader，之后1重启加入，3再次宕机，此时1、2感觉夯住了，cmd界面的日志一个动一个不动，然后选举过程始终无法进入；之后3重启，三进程开始疯狂互相连接，删除，bug！！！！感觉是网络传输层有问题！







**思路整理：**

prevote + fast election

尽可能保证最新数据节点当选，即使此数据未被提交

**fast election**

因网络延迟等原因，分布式集群中leader发生宕机时，leader、follower节点间可能存在部分的数据差异，而新leader当选后，各节点的数据均以leader的数据为基准，所以为保证已经提交（或达到大多数同意）的数据不被删除，希望数据最新的节点可以当选成为新的leader，但由于各节点间缺乏全局视角，所以通过网络报文，交换各自数据状态，从而使得节点拥有全局状态信息，最终选出最优节点成为leader。

由于最终目的为选举出最优的节点成为leader，所以将自身数据状态这一概念提炼为选票，即初始时，各节点天然的认为自身即符合最优条件的节点，发送投给自身的选票即等同于告知其他节点本机当前的数据状态，收到此选票后，接收节点通过比较选票中的数据版本信息来进一步决定是否认可其他节点为新leader，即是否改投选票为其他节点；只要出现选票的更改，本节点就需要将此改变广播告知所有的节点，此时如果数据版本信息是严格大于，不存在等于，那么通过各节点间多轮相互广播，最终可选出唯一一台节点作为半数以上认可的新leader。

但是因网络等现实因素的存在，当选节点不一定是最优节点，因为最优的节点可能才刚开始发出选票或者排到了接收方的网络接收队列的后方，还未被处理，这时其他节点的选举已经结束，导致最优节点被漏掉了。所以各节点尽可能同时发起选举，此外在各节点最终确定自身状态前，等待一段时间，此时段内若有新选票到来则推迟确定状态，否则直接确定状态，即尽可能等待所有节点的选票到达。



因leader宕机很可能发生多次，每次宕机后均会发起选举，各次宕机选举之间应该为互不干扰，所以节点需要维护当前的term或epoch，标明当前所在的任期（即哪台节点为leader，而且即使相邻两次选举，选出同一台节点（原leader马上恢复）为leader，这也属于两个term），只有节点处于同一term才能有效的参加选举；另外为保证数据的比较是严格大于的，选票比较时，除比较数据版本信息外，若版本相同则比较选票的服务器id，由此可保证数据必然存在大于。

整体选举流程如下：

![fast election流程图](F:\Markdown\研一上\图片\fast election流程图.png)

**prevote**

集群冷启动时，由于无法同时启动所有服务器，所以选择在配置文件中人为选定某主机作为leader，根据当前的”小ip连接大ip“的网络特性，建议小ip主机作为初始leader；启动后，leader会发出心跳报文，保持集群连通性，同时维持当前leader的任期，如果出现leader服务器宕机，剩余服务器会检测心跳报文超时次数，超时出现5次以上，即判定与leader断开连接（即election timeout = 5 * 心跳包超时时间）。但由于集群中各服务器缺乏全局视角，各节点仅能判断本机与当前leader断开连接，贸然发起选举，可能出现集群“脑裂”现象；

所以引入类似raft中prevote机制，即在选举之前，各节点维护一张各节点与当前leader的连通性表，即主观下线表（subjectiveFailMap_），同时交换各自与leader之间的连通性。节点收到来自其他节点的主观下线报文后，判断自身与leader连通性，并更新主观下线表，如果表格中半数以上节点与当前leader断开连接，则客观上判定leader已掉线，可以发起新一轮的选举fast election。最先判定leader客观下线的节点将广播告知所有现存活节点：leader已客观下线，可以发起选举，同时自身也主动发起选举。此模式下各节点基本可保证几乎同时发起选举，因最早发起选举的节点最多早RTTs发起选举，此时各节点也已开始选举，杜绝了选票被无视等情况，亦保证了fast election算法中各节点尽可能同时发起选举的前提条件。



但此时也引入了新的问题，由于初始leader由配置文件指定，初始leader宕机后，选出新的leader，此时初始leader重启，会仍然认为自身为leader，从而发出心跳包，所以当前集群中节点会收到错误的心跳信息，错误的重置自身的选举定时器，集群出现两个leader。

为防止此现象发生，节点收到心跳包后，会先行检查心跳包的发出方是否为当前的leader，若来自其他节点（如宕机后重启的初始leader）会发送纠错报文，告知其当前实际leader，错误心跳的发出方会统计此类纠错报文，达到半数以上即选择信任此纠错报文，更新自身状态，成为follower加入集群；不过此机制下，同样会导致错误，如经过一段时间运行，初始leader已转变为follower，此时另一follower宕机重启，在此follower的配置文件中leader应该为初始leader，所以错误的向当前leader发出了纠错报文，此时需要当前leader直接纠正此状态错误，防止follower无法加入现有集群。（但是此报文不可能累计半数以上，因为半数以上发出错误的纠错，就代表着半数以上服务器重启，即集群已经整体宕机，已无法对外提供服务）

纠错报文的机制类似于各节点间发起了仅维持一轮的fast election，且不会多次广播。





>  **raft中prevote**
>
>  由最早达到选举超时的节点1，广播预投票请求，接收方会检查自身与leader连通性，同时检查收到的选票中term和index信息，两者均通过则同意此投票请求，节点1获得半数以上的同意才可以真正发起投票。
>
>  仅用来预防网络分区时的”假阳性“问题，如果该最新数据未能在半数以上节点中存在，那么该最新数据节点就有可能落选！raft中允许此类情况，因为raft的保证为：数据在半数以上节点提交后必然不会被删除，如果最新数据未被提交，就有可能落选

